{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"C:\\\\Users\\\\carsten\\\\Desktop\\\\JuliaWorkshop19\\\\2_Two\\\\3_machine_learning\\\\zygote\\\\\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning in Julia: Flux.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://fluxml.ai/logo.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../flux.png\" width=900>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web page: https://fluxml.ai/\n",
    "\n",
    "Examples: [Model zoo](https://github.com/FluxML/model-zoo/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A single neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model (generic function with 2 methods)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x) = σ.(W * x + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       " 0.4256275822507929\n",
       " 0.9702364215891386\n",
       " 0.3290662609566366\n",
       " 0.5213958926845632\n",
       " 0.5929071691174677"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single neuron 5 in 1 out\n",
    "W = randn(1, 5) # weights\n",
    "b = zeros(1)    # biases\n",
    "x = rand(5)     # input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Float64,1}:\n",
       " 0.2177697408997619"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 2 methods)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x) = Flux.mse(model(x), 0.5) # mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07965391915178754"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-0.0409256 -0.0932918 … -0.0501341 -0.0570102], [-0.0961536], [0.0750345, 0.130382, -0.0681548, -0.0227079, -0.00205534])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad = gradient(loss, W, b, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use these gradients to update our parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update weights and biases\n",
    "\n",
    "η = 0.1\n",
    "for (i, p) in enumerate((W, b))\n",
    "  p .-= η * grad[i] # gradient descent\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(x) = 0.0408240348849211\n"
     ]
    }
   ],
   "source": [
    "# repeat a couple of times\n",
    "\n",
    "grad = gradient(loss, W, b, x)\n",
    "\n",
    "η = 0.1\n",
    "for (i, p) in enumerate((W, b))\n",
    "  p .-= η * grad[i] # gradient descent\n",
    "end\n",
    "\n",
    "@show loss(x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, Flux offers more sophisticated optimizers, like [stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our full deep learning code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Chain(\n",
    "    Dense(10, 5),\n",
    "    Dense(5, 2),\n",
    "    softmax # normalize output neurons\n",
    ")\n",
    "\n",
    "opt = ADAM(0.01)\n",
    "\n",
    "data, labels = rand(10, 100), fill(0.5, 2, 100)\n",
    "\n",
    "loss(x, y) = sum(Flux.mse(m(x), y))\n",
    "\n",
    "Flux.train!(loss, params(m), [(data,labels)], opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015583558094548623"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Statistics\n",
    "# loss before training\n",
    "mean(loss(data[:,i],labels[:,i]) for i in 1:100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008413629815947827"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Flux.train!(loss, params(m), [(data,labels)], opt)\n",
    "\n",
    "# loss after training\n",
    "mean(loss(data[:,i],labels[:,i]) for i in 1:100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using BenchmarkTools.params in module Main conflicts with an existing identifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  955.648 ms (28965221 allocations: 587.11 MiB)\n"
     ]
    }
   ],
   "source": [
    "using Flux, BenchmarkTools\n",
    "using Flux: crossentropy, onecold, onehotbatch, throttle, @epochs\n",
    "using Printf, Statistics, Random\n",
    "using Base.Iterators: repeated\n",
    "\n",
    "confs_left = rand(64,4000)\n",
    "confs_right = rand(64,4000)\n",
    "\n",
    "# set up as training data\n",
    "neach = size(confs_left, 2)\n",
    "X = hcat(confs_left, confs_right)\n",
    "labels = vcat(fill(1, neach), fill(0, neach))\n",
    "Y = onehotbatch(labels, 0:1)\n",
    "dataset = repeated((X, Y), 10)\n",
    "\n",
    "# create neural network with 10 hidden units and 2 output neurons\n",
    "Random.seed!(123)\n",
    "m = Chain(\n",
    "  Dense(64, 10, relu),\n",
    "  Dense(10, 2),\n",
    "  softmax)\n",
    "\n",
    "# define cost-function\n",
    "loss(x, y) = crossentropy(m(x), y)\n",
    "accuracy(x, y) = mean(onecold(m(x)) .== onecold(y))\n",
    "\n",
    "opt = ADAM()\n",
    "\n",
    "println(\"-------- Training\")\n",
    "@btime Flux.train!($loss, params($m), $dataset, $opt)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
