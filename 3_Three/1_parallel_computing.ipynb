{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel computing is a programming method that **harnesses the power of multiple processors (or cores) at once**. Once of concern only to programmers of large supercomputers, modern computers now almost always have multi-core processors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many CPU cores do I have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Hwloc\n",
    "Hwloc.num_physical_cores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sys.CPU_THREADS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that `Sys.CPU_THREADS` may or may not be equal to the number above. It indicates the number of CPUs + Hyperthreads.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why go parallel?\n",
    "\n",
    "<img src=\"42-years-processor-trend.svg\" width=700px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Amdahl's Law**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive expectation: I have 4 cores, give me my 4x speedup!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">If $p$ is the fraction of a code that can be parallelized than the maximal theoretical speedup by parallelizing on $n$ cores is given by $F(n) = 1/(1-p + p/n)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip5600\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip5600)\" points=\"\n",
       "0,1600 2400,1600 2400,0 0,0 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip5601\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip5600)\" points=\"\n",
       "202.373,1425.62 2352.76,1425.62 2352.76,47.2441 202.373,47.2441 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip5602\">\n",
       "    <rect x=\"202\" y=\"47\" width=\"2151\" height=\"1379\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip5602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  533.721,1425.62 533.721,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  939.454,1425.62 939.454,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1345.19,1425.62 1345.19,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1750.92,1425.62 1750.92,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2156.65,1425.62 2156.65,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  202.373,1213.23 2352.76,1213.23 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  202.373,953.157 2352.76,953.157 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  202.373,693.086 2352.76,693.086 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  202.373,433.016 2352.76,433.016 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5602)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  202.373,172.945 2352.76,172.945 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  202.373,1425.62 2352.76,1425.62 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  202.373,1425.62 202.373,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  533.721,1425.62 533.721,1404.94 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  939.454,1425.62 939.454,1404.94 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1345.19,1425.62 1345.19,1404.94 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1750.92,1425.62 1750.92,1404.94 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2156.65,1425.62 2156.65,1404.94 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  202.373,1213.23 234.629,1213.23 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  202.373,953.157 234.629,953.157 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  202.373,693.086 234.629,693.086 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  202.373,433.016 234.629,433.016 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  202.373,172.945 234.629,172.945 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip5600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 533.721, 1479.62)\" x=\"533.721\" y=\"1479.62\">3</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip5600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 939.454, 1479.62)\" x=\"939.454\" y=\"1479.62\">6</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip5600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1345.19, 1479.62)\" x=\"1345.19\" y=\"1479.62\">9</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip5600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1750.92, 1479.62)\" x=\"1750.92\" y=\"1479.62\">12</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip5600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 2156.65, 1479.62)\" x=\"2156.65\" y=\"1479.62\">15</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip5600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 178.373, 1230.73)\" x=\"178.373\" y=\"1230.73\">3</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip5600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 178.373, 970.657)\" x=\"178.373\" y=\"970.657\">6</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip5600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 178.373, 710.586)\" x=\"178.373\" y=\"710.586\">9</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip5600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 178.373, 450.516)\" x=\"178.373\" y=\"450.516\">12</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip5600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 178.373, 190.445)\" x=\"178.373\" y=\"190.445\">15</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip5602)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  202.373,47.2441 2352.76,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5602)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2352.76,1425.62 2352.76,47.2441 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip5600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(0, 1277.56, 1559.48)\" x=\"1277.56\" y=\"1559.48\">number of cores</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip5600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(-90, 89.2861, 736.431)\" x=\"89.2861\" y=\"736.431\">parallel speedup</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip5602)\" style=\"stroke:#009af9; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  263.233,1386.61 398.477,1299.92 533.721,1213.23 668.965,1126.54 804.21,1039.85 939.454,953.157 1074.7,866.467 1209.94,779.776 1345.19,693.086 1480.43,606.396 \n",
       "  1615.67,519.706 1750.92,433.016 1886.16,346.325 2021.41,259.635 2156.65,172.945 2291.9,86.2547 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5602)\" style=\"stroke:#e26f46; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  263.233,1386.61 398.477,1308.17 533.721,1236.87 668.965,1171.77 804.21,1112.09 939.454,1057.19 1074.7,1006.5 1209.94,959.578 1345.19,916.004 1480.43,875.435 \n",
       "  1615.67,837.57 1750.92,802.148 1886.16,768.94 2021.41,737.745 2156.65,708.385 2291.9,680.702 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5602)\" style=\"stroke:#3da44d; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  263.233,1386.61 398.477,1315.68 533.721,1256.57 668.965,1206.56 804.21,1163.69 939.454,1126.54 1074.7,1094.03 1209.94,1065.34 1345.19,1039.85 1480.43,1017.03 \n",
       "  1615.67,996.502 1750.92,977.926 1886.16,961.038 2021.41,945.619 2156.65,931.484 2291.9,918.481 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5602)\" style=\"stroke:#c271d2; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  263.233,1386.61 398.477,1328.81 533.721,1287.53 668.965,1256.57 804.21,1232.49 939.454,1213.23 1074.7,1197.47 1209.94,1184.33 1345.19,1173.22 1480.43,1163.69 \n",
       "  1615.67,1155.43 1750.92,1148.21 1886.16,1141.84 2021.41,1136.17 2156.65,1131.1 2291.9,1126.54 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5602)\" style=\"stroke:#ac8d18; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  263.233,1386.61 398.477,1349.46 533.721,1328.81 668.965,1315.68 804.21,1306.59 939.454,1299.92 1074.7,1294.82 1209.94,1290.79 1345.19,1287.53 1480.43,1284.84 \n",
       "  1615.67,1282.58 1750.92,1280.65 1886.16,1278.99 2021.41,1277.55 2156.65,1276.28 2291.9,1275.15 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5602)\" style=\"stroke:#00a9ad; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  263.233,1386.61 398.477,1364.94 533.721,1355.08 668.965,1349.46 804.21,1345.81 939.454,1343.26 1074.7,1341.38 1209.94,1339.93 1345.19,1338.78 1480.43,1337.84 \n",
       "  1615.67,1337.07 1750.92,1336.42 1886.16,1335.86 2021.41,1335.38 2156.65,1334.96 2291.9,1334.59 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5602)\" style=\"stroke:#ed5d92; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  263.233,1386.61 398.477,1376.98 533.721,1373.27 668.965,1371.31 804.21,1370.1 939.454,1369.27 1074.7,1368.67 1209.94,1368.22 1345.19,1367.86 1480.43,1367.58 \n",
       "  1615.67,1367.34 1750.92,1367.15 1886.16,1366.98 2021.41,1366.84 2156.65,1366.71 2291.9,1366.6 \n",
       "  \"/>\n",
       "<polygon clip-path=\"url(#clip5600)\" points=\"\n",
       "274.373,614.604 637.451,614.604 637.451,130.764 274.373,130.764 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip5600)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  274.373,614.604 637.451,614.604 637.451,130.764 274.373,130.764 274.373,614.604 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip5600)\" style=\"stroke:#009af9; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  298.373,191.244 442.373,191.244 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip5600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 466.373, 208.744)\" x=\"466.373\" y=\"208.744\">100%</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip5600)\" style=\"stroke:#e26f46; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  298.373,251.724 442.373,251.724 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip5600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 466.373, 269.224)\" x=\"466.373\" y=\"269.224\">95%</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip5600)\" style=\"stroke:#3da44d; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  298.373,312.204 442.373,312.204 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip5600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 466.373, 329.704)\" x=\"466.373\" y=\"329.704\">90%</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip5600)\" style=\"stroke:#c271d2; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  298.373,372.684 442.373,372.684 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip5600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 466.373, 390.184)\" x=\"466.373\" y=\"390.184\">80%</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip5600)\" style=\"stroke:#ac8d18; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  298.373,433.164 442.373,433.164 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip5600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 466.373, 450.664)\" x=\"466.373\" y=\"450.664\">60%</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip5600)\" style=\"stroke:#00a9ad; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  298.373,493.644 442.373,493.644 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip5600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 466.373, 511.144)\" x=\"466.373\" y=\"511.144\">40%</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip5600)\" style=\"stroke:#ed5d92; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  298.373,554.124 442.373,554.124 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip5600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 466.373, 571.624)\" x=\"466.373\" y=\"571.624\">20%</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "F(p,n) = 1/(1-p + p/n)\n",
    "\n",
    "pl = plot()\n",
    "for p in reverse(sort(vcat(0.2:0.2:1, [0.9, 0.95])))\n",
    "    plot!(pl, n -> F(p,n), 1:16, lab=\"$(Int(p*100))%\", lw=2,\n",
    "        legend=:topleft, xlab=\"number of cores\", ylab=\"parallel speedup\", frame=:box)\n",
    "end\n",
    "pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Computing in Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia documentation link: [Parallel computing](https://docs.julialang.org/en/v1/manual/parallel-computing/index.html)\n",
    "\n",
    "There are many types of parallelism, some of which are (from micro to macro)\n",
    "\n",
    "* **Instruction level parallelism**\n",
    "* **Multi-threading** (process shared memory)\n",
    "* **Tasks aka Coroutines** aka Green threads (more like cooperative multitasking, process shared memory)\n",
    "* **Multi-Core processing** (maybe system shared memory)\n",
    "* **Distributed processing** (same as above but involving multiple machines)\n",
    "\n",
    "Julia provides (more or less) native support for all of these forms of parallel processing (same order as above)\n",
    "\n",
    "* `@simd` and [SIMD.jl](https://github.com/eschnett/SIMD.jl)\n",
    "* `Base.Threads.@threads` (experimental since 2015 but seems to be fine)\n",
    "* `@async`, `@sync`, `Channel`\n",
    "* `@spawnat`, `@fetch`, `RemoteChannel`, `SharedArray`, etc.\n",
    "* `@spawnat`, `@fetch`, `RemoteChannel`, `DArray`, `MPI.jl` etc.\n",
    "\n",
    "With scientific computing in mind, we will mainly focus on how to distribute a process through multiple cores or machines (our thp cluster for example), that is **Multi-Core processing** and **Distributed processing**. But before we can do so, we have to learn how to control Julia's control flow through tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks (Control flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Julia waits for every command to finish and run everything sequentially.\n",
    "\n",
    "Tasks are a control flow feature that allows computations to be **suspended** and resumed in a flexible manner. This feature is sometimes called by other names, such as coroutines, green or lightweight threads and cooperative multitasking.\n",
    "\n",
    "To me, the name **cooperative multitasking** is the most descriptive. Tasks are managed/scheduled by Julia and can sometimes be run in a quasi-parallel fashion.\n",
    "\n",
    "An important use case is **asynchronous I/O**, which is typically slow. Examples are\n",
    " * **multiple user input** (Why not already process some of the input?)\n",
    " * **data dumping to disk** (Maybe it's possible to continue a calculation?)\n",
    " * **receiving calculations from worker processes** (We'll need that below!)\n",
    "\n",
    "How do we execute commands asynchronously?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `@async` and `@sync`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Based on [this](https://stackoverflow.com/questions/37287020/how-and-when-to-use-async-and-sync-in-julia/37287021#37287021) stackoverflow answer.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "@async\n",
       "\\end{verbatim}\n",
       "Wrap an expression in a \\href{@ref}{\\texttt{Task}} and add it to the local machine's scheduler queue.\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "@async\n",
       "```\n",
       "\n",
       "Wrap an expression in a [`Task`](@ref) and add it to the local machine's scheduler queue.\n"
      ],
      "text/plain": [
       "\u001b[36m  @async\u001b[39m\n",
       "\n",
       "  Wrap an expression in a \u001b[36mTask\u001b[39m and add it to the local machine's scheduler\n",
       "  queue."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?@async"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this means is that for whatever falls within its scope, Julia will start a task to then proceed to whatever comes next in the script **without waiting for the task to complete**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.031998 seconds (82.55 k allocations: 4.324 MiB)\n"
     ]
    }
   ],
   "source": [
    "@time sleep(2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.006419 seconds (6.72 k allocations: 385.456 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Task (runnable) @0x00000000341dc2f0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time @async sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia allows the script to proceed (and the `@time` macro to fully execute) without waiting for the task (in this case, sleeping for two seconds) to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `@sync` macro to synchronize, that is wait for, all encapsulated tasks. (see `?@sync`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.031486 seconds (16.52 k allocations: 782.446 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Task (done) @0x000000002f3bc2f0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time @sync @async sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, here it doesn't make much sense to write `@sync @async` - we could simply drop it altogether.\n",
    "\n",
    "A better example is the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.028964 seconds (13.29 k allocations: 732.489 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Task (done) @0x000000002f3bdcd0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time @sync begin\n",
    "    @async sleep(2.0)\n",
    "    @async sleep(2.0)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello class!\n",
      "Today is reverse day!\n"
     ]
    }
   ],
   "source": [
    "@sync begin\n",
    "    @async (sleep(2); println(\"Today is reverse day!\"))\n",
    "    @async (sleep(1); println(\" class!\"))\n",
    "    @async print(\"Hello\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed processing: Multi-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed computing in Julia means having **multiple separate Julia instances running on different cores** on the same or different machines.\n",
    "\n",
    "Data movement and communication between processes is explicit.\n",
    "\n",
    "Let's focus on the *multi-core* case (your laptop/desktop) and save some cluster fun for later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master-worker model\n",
    "\n",
    "Julia uses a *master-worker* paradigm for its native distributed parallelism.\n",
    "\n",
    "One master process coordinates all the worker processes, which perform the actual computations.\n",
    "\n",
    "By default, Julia starts with one process on one core. If this single process is all we have, than it is both the master and the worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed # Loading all tools that we need for distributed computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nprocs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nworkers() # the master is considered a worker as long as there are no real workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To increase the number of workers, i.e. Julia processes, from within a Julia session we can use `addprocs`.\n",
    "\n",
    "Alternatively, when starting Julia from the command line, one can use the `-p` option. Example,\n",
    "\n",
    "```\n",
    "julia -p 4\n",
    "```\n",
    "\n",
    "will start Julia with 5 processes, 1 master and 4 workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs(4) # I have 4 cores, so let's add 4 worker processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every process has a Julia internal `pid` (process id). The master is always 1. You can get the workers pids from `workers()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the 4 worker's pids aren't necessarily 2, 3, 4 and 5. Let's remove the processes and add them once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (done) @0x000000002f8f2b30"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmprocs(workers()) # rmprocs(array of pids of worker processes to remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nworkers() # only the master is left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One master to rule them all - `@spawn`, `@spawnat`, `@fetch`, `@fetchfrom`, `@everywhere`..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute commands and start computations on workers we can use the following macros\n",
    "\n",
    "* `@spawn`: run a command or a code block on any worker and return a `Future` to it's result. It's basically a version of `@async` for remote processes.\n",
    "* `@spawnat`: same as `@spawn` but one can choose a specific worker by providing its pid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Let's say we would like to generate a random matrix on one of the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Future(6, 1, 10, nothing)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@spawn rand(2,2) # basically @async for remote process, i.e. returns immediately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Future(7, 1, 11, nothing)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = @spawn rand(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 0.809299  0.509393\n",
       " 0.852996  0.512583"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch(result) # blocks, like @sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the combination of spawning at fetching is so common, there is `@fetch` which combines them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 0.8263    0.864689\n",
       " 0.732377  0.100403"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@fetch rand(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which worker did the work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 7:\t7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 0.229717  0.759929\n",
       " 0.14889   0.752025"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@fetch begin\n",
    "    println(myid());\n",
    "    rand(2,2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `@spawnat` and `@fetchfrom` we can delegate the work to a specific worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 8:\t8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 0.261581  0.784215\n",
       " 0.462334  0.938527"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@fetchfrom workers()[3] begin\n",
    "    println(myid());\n",
    "    rand(2,2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `@sync` as a blocker to wait for all workers to complete their tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 8:\tHello\n",
      "      From worker 7:\t class!\n",
      "      From worker 6:\tToday is reverse day!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "@sync begin\n",
    "    pids = workers()\n",
    "    @spawnat pids[1] (sleep(2); println(\"Today is reverse day!\"))\n",
    "    @spawnat pids[2] (sleep(1); println(\" class!\"))\n",
    "    @spawnat pids[3] println(\"Hello\")\n",
    "end;\n",
    "println(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we understood all that, let's delegate a *complicated* calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RemoteException",
     "evalue": "On worker 8:\nUndefVarError: #complicated_calculation not defined\ndeserialize_datatype at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Serialization\\src\\Serialization.jl:1186\nhandle_deserialize at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Serialization\\src\\Serialization.jl:775\ndeserialize at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Serialization\\src\\Serialization.jl:722\nhandle_deserialize at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Serialization\\src\\Serialization.jl:782\ndeserialize_global_from_main at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Serialization\\src\\Serialization.jl:722\n#5 at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Distributed\\src\\clusterserialize.jl:72 [inlined]\nforeach at .\\abstractarray.jl:1920\ndeserialize at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Distributed\\src\\clusterserialize.jl:72\nhandle_deserialize at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Serialization\\src\\Serialization.jl:860\ndeserialize at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Serialization\\src\\Serialization.jl:722\nhandle_deserialize at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Serialization\\src\\Serialization.jl:779\ndeserialize at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Serialization\\src\\Serialization.jl:722\nhandle_deserialize at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Serialization\\src\\Serialization.jl:782\ndeserialize_msg at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Serialization\\src\\Serialization.jl:722\n#invokelatest#1 at .\\essentials.jl:790 [inlined]\ninvokelatest at .\\essentials.jl:789 [inlined]\nmessage_handler_loop at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Distributed\\src\\process_messages.jl:183\nprocess_tcp_streams at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Distributed\\src\\process_messages.jl:140\n#105 at .\\task.jl:268",
     "output_type": "error",
     "traceback": [
      "On worker 8:\nUndefVarError: #complicated_calculation not defined\ndeserialize_datatype at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Serialization\\src\\Serialization.jl:1186\nhandle_deserialize at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Serialization\\src\\Serialization.jl:775\ndeserialize at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Serialization\\src\\Serialization.jl:722\nhandle_deserialize at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Serialization\\src\\Serialization.jl:782\ndeserialize_global_from_main at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Serialization\\src\\Serialization.jl:722\n#5 at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Distributed\\src\\clusterserialize.jl:72 [inlined]\nforeach at .\\abstractarray.jl:1920\ndeserialize at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Distributed\\src\\clusterserialize.jl:72\nhandle_deserialize at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Serialization\\src\\Serialization.jl:860\ndeserialize at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Serialization\\src\\Serialization.jl:722\nhandle_deserialize at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Serialization\\src\\Serialization.jl:779\ndeserialize at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Serialization\\src\\Serialization.jl:722\nhandle_deserialize at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Serialization\\src\\Serialization.jl:782\ndeserialize_msg at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Serialization\\src\\Serialization.jl:722\n#invokelatest#1 at .\\essentials.jl:790 [inlined]\ninvokelatest at .\\essentials.jl:789 [inlined]\nmessage_handler_loop at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Distributed\\src\\process_messages.jl:183\nprocess_tcp_streams at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Distributed\\src\\process_messages.jl:140\n#105 at .\\task.jl:268",
      "",
      "Stacktrace:",
      " [1] #remotecall_fetch#149 at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Distributed\\src\\remotecall.jl:379 [inlined]",
      " [2] remotecall_fetch(::Function, ::Distributed.Worker) at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Distributed\\src\\remotecall.jl:371",
      " [3] #remotecall_fetch#152(::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::typeof(remotecall_fetch), ::Function, ::Int64) at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Distributed\\src\\remotecall.jl:406",
      " [4] remotecall_fetch(::Function, ::Int64) at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Distributed\\src\\remotecall.jl:406",
      " [5] top-level scope at In[46]:7"
     ]
    }
   ],
   "source": [
    "using Random\n",
    "\n",
    "function complicated_calculation()\n",
    "    sleep(1) # so complex that it takes a long time :)\n",
    "    randexp(5)\n",
    "end\n",
    "\n",
    "@fetch complicated_calculation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Think of every worker as a separate Julia instance.**\n",
    "\n",
    "We only defined `complicated_calculation()` on the master process. The function doesn't exist on any of the workers yet.\n",
    "\n",
    "The macro `@everywhere` comes for the rescue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere begin # execute this block on all workers\n",
    "    using Random\n",
    "    \n",
    "    function complicated_calculation()\n",
    "        sleep(1)\n",
    "        randexp(5) # lives in Random\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       " 0.9722616638822857\n",
       " 2.420641109202318 \n",
       " 2.1362605354866755\n",
       " 0.1815570007654114\n",
       " 1.0104508793550906"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@fetch complicated_calculation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data movement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a crucial difference between the following two pieces of code. Can you guess what it is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method1 (generic function with 1 method)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function method1()\n",
    "    A = rand(100,100)\n",
    "    B = rand(100,100)\n",
    "    C = @fetch A^2 * B^2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method2 (generic function with 1 method)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function method2()\n",
    "    C = @fetch rand(100,100)^2 * rand(100,100)^2\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's benchmark them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  435.900 μs (133 allocations: 239.00 KiB)\n",
      "  349.800 μs (103 allocations: 82.02 KiB)\n"
     ]
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "@btime method1();\n",
    "@btime method2();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1 is slower, because `A` and `B` are created on the master process, transferred to a worker, and squared and multiplied on the worker process before the result is finally transferred back to the master.\n",
    "\n",
    "Method 2, on the other hand, creates, squares, and multiplies the random matrix all on the work process and only submits the result to the master.\n",
    "\n",
    "Hence, `method1` is **transferring 3x as much data** between the master and the worker!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data movement is crucial!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this toy example, it's rather easy to identify the faster method.\n",
    "\n",
    "In a real program, however, understanding data movement does require more thought and likely some measurement.\n",
    "\n",
    "For example, if the first process needs matrix `A` in a follow-up computation then the first method might be better in this case. Or, if computing `A` is expensive and only the current process has it, then moving it to another process might be unavoidable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computer latency at a human scale\n",
    "\n",
    "To understand why thinking about data is important it's instructive to look at the time scales involved in data access.\n",
    "\n",
    "<img src=\"latency_human_scales.png\" width=900px>\n",
    "\n",
    "(taken from https://www.prowesscorp.com/computer-latency-at-a-human-scale/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoid globals (once more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myglobal = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "whohas (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function whohas(s::String)\n",
    "    @everywhere begin\n",
    "        var = Symbol($s)\n",
    "        if isdefined(Main, var)\n",
    "            println(\"$var exists.\")\n",
    "        else\n",
    "            println(\"Doesn't exist.\")\n",
    "        end\n",
    "    end\n",
    "    nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myglobal exists.\n",
      "      From worker 6:\tDoesn't exist.\n",
      "      From worker 7:\tDoesn't exist.\n",
      "      From worker 8:\tDoesn't exist.\n",
      "      From worker 9:\tDoesn't exist.\n"
     ]
    }
   ],
   "source": [
    "whohas(\"myglobal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@fetchfrom workers()[1] myglobal+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myglobal exists.\n",
      "      From worker 6:\tmyglobal exists.\n",
      "      From worker 8:\tDoesn't exist.\n",
      "      From worker 7:\tDoesn't exist.\n",
      "      From worker 9:\tDoesn't exist.\n"
     ]
    }
   ],
   "source": [
    "whohas(\"myglobal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Globals get copied to workers and continue to exist as globals even after the call.\n",
    "\n",
    "This could lead to memory accumulation if many globals are used (just as it would in a single Julia session).\n",
    "\n",
    "It's better to avoid them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit data movement: `Channel` and `RemoteChannel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Channels in Julia are constructs to explicitly exchange data between workers.\n",
    "\n",
    "They implement `put!`, `take!`, `fetch`, `isready` and `wait` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ?Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Channel{Int64}(sz_max:5,sz_curr:0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch = Channel{Int}(5) # a channel that can hold up to 5 integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isready(ch) # something in the channel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "put!(ch, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isready(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take!(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isready(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "put!(ch, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch(ch) # basically take without a bang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take!(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful, `take!` and `put!` are blocking if the channel is empty or full!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isready(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take!(ch) if we execute this, while isready(ch) == false, the current Julia session will hang."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channels for inter-process data movement: `RemoteChannel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A `Channel` is local to a process. Worker 2 cannot directly refer to a `Channel` on worker 3 and vice-versa.\n",
    "\n",
    "\n",
    "* A `RemoteChannel`, however, can put and take values across workers. A `RemoteChannel` can be thought of as a handle to a `Channel`.\n",
    "\n",
    "\n",
    "* Any process with a reference to a `RemoteChannel` can put and take items from the channel. Data is automatically sent to (or retrieved from) the process a `RemoteChannel` is associated with.\n",
    "\n",
    "\n",
    "* The process id, pid, associated with a `RemoteChannel` identifies the process where the backing store, i.e., the backing Channel exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nworkers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mR\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mC\u001b[22m\u001b[0m\u001b[1mh\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1ml\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "RemoteChannel(pid::Integer=myid())\n",
       "\\end{verbatim}\n",
       "Make a reference to a \\texttt{Channel\\{Any\\}(1)} on process \\texttt{pid}. The default \\texttt{pid} is the current process.\n",
       "\n",
       "\\begin{verbatim}\n",
       "RemoteChannel(f::Function, pid::Integer=myid())\n",
       "\\end{verbatim}\n",
       "Create references to remote channels of a specific size and type. \\texttt{f} is a function that when executed on \\texttt{pid} must return an implementation of an \\texttt{AbstractChannel}.\n",
       "\n",
       "For example, \\texttt{RemoteChannel(()->Channel\\{Int\\}(10), pid)}, will return a reference to a channel of type \\texttt{Int} and size 10 on \\texttt{pid}.\n",
       "\n",
       "The default \\texttt{pid} is the current process.\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "RemoteChannel(pid::Integer=myid())\n",
       "```\n",
       "\n",
       "Make a reference to a `Channel{Any}(1)` on process `pid`. The default `pid` is the current process.\n",
       "\n",
       "```\n",
       "RemoteChannel(f::Function, pid::Integer=myid())\n",
       "```\n",
       "\n",
       "Create references to remote channels of a specific size and type. `f` is a function that when executed on `pid` must return an implementation of an `AbstractChannel`.\n",
       "\n",
       "For example, `RemoteChannel(()->Channel{Int}(10), pid)`, will return a reference to a channel of type `Int` and size 10 on `pid`.\n",
       "\n",
       "The default `pid` is the current process.\n"
      ],
      "text/plain": [
       "\u001b[36m  RemoteChannel(pid::Integer=myid())\u001b[39m\n",
       "\n",
       "  Make a reference to a \u001b[36mChannel{Any}(1)\u001b[39m on process \u001b[36mpid\u001b[39m. The default \u001b[36mpid\u001b[39m is the\n",
       "  current process.\n",
       "\n",
       "\u001b[36m  RemoteChannel(f::Function, pid::Integer=myid())\u001b[39m\n",
       "\n",
       "  Create references to remote channels of a specific size and type. \u001b[36mf\u001b[39m is a\n",
       "  function that when executed on \u001b[36mpid\u001b[39m must return an implementation of an\n",
       "  \u001b[36mAbstractChannel\u001b[39m.\n",
       "\n",
       "  For example, \u001b[36mRemoteChannel(()->Channel{Int}(10), pid)\u001b[39m, will return a\n",
       "  reference to a channel of type \u001b[36mInt\u001b[39m and size 10 on \u001b[36mpid\u001b[39m.\n",
       "\n",
       "  The default \u001b[36mpid\u001b[39m is the current process."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?RemoteChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq(x) = x^2\n",
    "function sq(x)\n",
    "    x^2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#5 (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = x -> x^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Array{Int64,1}:\n",
       "  1\n",
       " -3\n",
       "  4\n",
       " -8\n",
       " 10\n",
       "  5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,-3,4,-8,10,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mystupidfunction (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mystupidfunction(y)\n",
    "    if iseven(y) && y<0\n",
    "        return true\n",
    "    else\n",
    "        return false\n",
    "    end\n",
    "end     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y -> x^2 + y^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Int64,1}:\n",
       " -8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter((y) -> iseven(y) && y<0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RemoteChannel{Channel{Int64}}(3, 1, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a channel on the second worker process\n",
    "# create a RemoteChannel handle to this channel on the master process\n",
    "const mychannel = RemoteChannel(()->Channel{Int}(10), workers()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mychannel exists.\n",
      "      From worker 3:\tDoesn't exist.\n",
      "      From worker 4:\tDoesn't exist.\n",
      "      From worker 2:\tDoesn't exist.\n",
      "      From worker 6:\tDoesn't exist.\n",
      "      From worker 5:\tDoesn't exist.\n",
      "      From worker 7:\tDoesn't exist.\n",
      "      From worker 8:\tDoesn't exist.\n",
      "      From worker 9:\tDoesn't exist.\n"
     ]
    }
   ],
   "source": [
    "whohas(\"mychannel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One could create a global constant mychannel everywhere\n",
    "@everywhere const mychannel = $mychannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mychannel exists.\n",
      "      From worker 2:\tmychannel exists.\n",
      "      From worker 4:\tmychannel exists.\n",
      "      From worker 6:\tmychannel exists.\n",
      "      From worker 7:\tmychannel exists.\n",
      "      From worker 8:\tmychannel exists.\n",
      "      From worker 9:\tmychannel exists.\n",
      "      From worker 5:\tmychannel exists.\n",
      "      From worker 3:\tmychannel exists.\n"
     ]
    }
   ],
   "source": [
    "whohas(\"mychannel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as we said many times before, one should generally try to avoid globals. The following is preferable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RemoteChannel{Channel{Int64}}(1, 1, 60)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function do_something()\n",
    "    rc = RemoteChannel(()->Channel{Int}(10)) # lives on the master\n",
    "    @sync for p in workers()\n",
    "        @spawnat p put!(rc, myid())\n",
    "    end\n",
    "    rc\n",
    "end\n",
    "\n",
    "r = do_something()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isready(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take!(r) = 3\n",
      "take!(r) = 7\n",
      "take!(r) = 5\n",
      "take!(r) = 6\n",
      "take!(r) = 4\n",
      "take!(r) = 2\n",
      "take!(r) = 8\n",
      "take!(r) = 9\n"
     ]
    }
   ],
   "source": [
    "while isready(r)\n",
    "    @show take!(r)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ecosystem also contains a couple of tools, that make data transfer even simpler. See for example [ParallelDataTransfer.jl](https://github.com/ChrisRackauckas/ParallelDataTransfer.jl/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelizing the easy way - `@distributed` and `pmap`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have seen the build block of commands for distributed computing in Julia. Having scientific computing in mind, one might not always want to think about how to distribute the work and explicitly spawn tasks.\n",
    "\n",
    "Also, fortunately, many useful parallel computations do not require (much) data movement. A common example is a direct Monte Carlo simulation, where multiple processes can handle independent simulation trials simultaneously. (We'll get to that later!)\n",
    "\n",
    "Julia provides convenience macros to\n",
    " * Parallelize loops (`@distributed`)\n",
    " * Apply a function to all elements in some collection (`pmap`)\n",
    " \n",
    "Let's explore these!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed loops (`@distributed`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributed, BenchmarkTools; rmprocs(workers()); addprocs(4); nworkers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  270.357 ms (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "source": [
    "# serial version - count heads in a series of coin tosses\n",
    "function add_serial(n)\n",
    "    c = 0\n",
    "    for i = 1:n\n",
    "        c += rand(Bool)\n",
    "    end\n",
    "    c\n",
    "end\n",
    "\n",
    "@btime add_serial(200_000_000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is trivially parallelizable since the loop iterations are independent of each other. We can distribute coin tosses over a couple of workers.\n",
    "\n",
    "Afterwards we combine the results, that is we sum them up. The combination process is generally called a *reduction*, and in this case `sum` is the *reducer function*.\n",
    "\n",
    "To distribute the for loop over worker processes Julia provides the `@distributed` macro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?@distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  72.263 ms (448 allocations: 18.30 KiB)\n"
     ]
    }
   ],
   "source": [
    "# distributed version\n",
    "function add_distributed(n)\n",
    "    c = @distributed (+) for i in 1:n\n",
    "        Int(rand(Bool))\n",
    "    end\n",
    "    c\n",
    "end\n",
    "\n",
    "@btime add_distributed(200_000_000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributed version is about **4x faster**, which is all we could hope for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see who is doing the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 12:\t1\n",
      "      From worker 10:\t0\n",
      "      From worker 11:\t1\n",
      "      From worker 13:\t0\n",
      "      From worker 12:\t0\n",
      "      From worker 10:\t0\n",
      "      From worker 11:\t1\n",
      "      From worker 13:\t0\n"
     ]
    }
   ],
   "source": [
    "# verbose distributed version\n",
    "function add_distributed(n)\n",
    "    c = @distributed (+) for i in 1:n\n",
    "        x = Int(rand(Bool))\n",
    "        println(x);\n",
    "        x\n",
    "    end\n",
    "    c\n",
    "end\n",
    "\n",
    "add_distributed(8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, the work is evenly distributed between the workers. By using `@distributed` we let Julia decide how to split up the work and can't control it ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common mistake when using `@distributed` is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "function f(n)\n",
    "    a = 0\n",
    "    @distributed (+) for i in 1:n\n",
    "        a += 1\n",
    "    end\n",
    "    a\n",
    "end\n",
    "\n",
    "a = f(10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you expect the value of `a` to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can (sort of) see what's happening by making everything global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 11:\t1\n",
      "      From worker 12:\t1\n",
      "      From worker 13:\t1\n",
      "      From worker 10:\t1\n",
      "      From worker 11:\t1\n",
      "      From worker 11:\t1\n",
      "      From worker 12:\t1\n",
      "      From worker 13:\t1\n",
      "      From worker 10:\t1\n",
      "      From worker 10:\t1\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "@distributed (+) for i in 1:10\n",
    "    println(\"1\")\n",
    "    global a += 1\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 0\n",
      "      From worker 11:\ta = 3\n",
      "      From worker 12:\ta = 2\n",
      "      From worker 13:\ta = 2\n",
      "      From worker 10:\ta = 3\n"
     ]
    }
   ],
   "source": [
    "@everywhere @show a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `a` gets copied to the worker processes as it is referenced in the distributed loop. \n",
    "\n",
    "Every worker will then increment its copy of `a`.\n",
    "\n",
    "However, we do not save the result of the reduction (sum) but instead return `a` from the master process, which hasn't been altered at all.\n",
    "\n",
    "Corrected version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function f2(n)\n",
    "    a = @distributed (+) for i in 1:n\n",
    "        1\n",
    "    end\n",
    "    a\n",
    "end\n",
    "\n",
    "a = f2(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if I don't want to reduce?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the mistake above, the following example might not have the effect one expects. **Why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (runnable) @0x0000000010069cd0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = zeros(10)\n",
    "@distributed for i = 1:10\n",
    "    a[i] = i\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "      From worker 12:\ta = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 0.0]\n",
      "      From worker 10:\ta = [1.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "      From worker 11:\ta = [0.0, 0.0, 0.0, 4.0, 5.0, 6.0, 0.0, 0.0, 0.0, 0.0]\n",
      "      From worker 13:\ta = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 10.0]\n"
     ]
    }
   ],
   "source": [
    "@everywhere @show a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `@distributed` without a reduction function returns a `Task`. It is basically a distributed version of `@spawn` for all the iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `SharedArray`s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually make all processes operate on the same array, one can use a `SharedArray`.\n",
    "\n",
    "Note that a `SharedArray` only works if the **processes live on the same host**.\n",
    "\n",
    "The constructor of a SharedArray is\n",
    "\n",
    "```julia\n",
    "SharedArray{T,N}(dims::NTuple; init=false, pids=Int[])\n",
    "```\n",
    "\n",
    "which creates an `N`-dimensional shared array of a (bits) type `T` and size `dims` across the processes specified by `pids`.\n",
    "\n",
    "(If an `init` function, of signature `initfn(S::SharedArray)`, is specified, it is called on all the participating workers. You can specify that each worker runs the init function on a distinct portion of the array, thereby parallelizing initialization.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using SharedArrays # must be loaded everywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3 Array{Float64,2}:\n",
       " 0.0751331  0.530742  0.112325\n",
       " 0.410691   0.145509  0.579472"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = rand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3 SharedArray{Float64,2}:\n",
       " 0.0751331  0.530742  0.112325\n",
       " 0.410691   0.145509  0.579472"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = SharedArray(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we know how to create and fill our `SharedArray` we can create a parallel fill function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 SharedArray{Float64,2}:\n",
       " 0.0  0.0  0.0\n",
       " 0.0  0.0  0.0\n",
       " 0.0  0.0  0.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fill_shared_problematic(N)\n",
    "    S = SharedMatrix{Float64}(N,N)\n",
    "    @distributed for i in 1:length(S)\n",
    "        S[i] = i\n",
    "    end\n",
    "    S\n",
    "end\n",
    "\n",
    "fill_shared_problematic(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Why is the method in its current form problematic? Try to find out yourself by going to larger `N` and, for example, inspecting the minimum of the returned `SharedArray`!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to larger matrix sizes...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fill_shared_problematic(N)\n",
    "    S = SharedMatrix{Int64}(N,N)\n",
    "    @distributed for i in 1:length(S)\n",
    "        S[i] = i\n",
    "    end\n",
    "    S\n",
    "end\n",
    "\n",
    "S = fill_shared_problematic(100)\n",
    "minimum(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how sometimes the array isn't completely filled but still contains zeros. This is because it isn't filled **yet**!\n",
    "\n",
    "Check again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimum(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `@sync` to synchronize our distributed for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fill_shared_problematic(N)\n",
    "    S = SharedMatrix{Int64}(N,N)\n",
    "    @sync @distributed for i in 1:length(S) # added @sync here\n",
    "        S[i] = i\n",
    "    end\n",
    "    S\n",
    "end\n",
    "\n",
    "S = fill_shared_problematic(100)\n",
    "minimum(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's **benchmark** this for a larger matrix size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.258869 seconds (20.86 k allocations: 764.072 MiB, 5.42% gc time)\n"
     ]
    }
   ],
   "source": [
    "# regular array\n",
    "function fill_regular(N)\n",
    "    A = Matrix{Int64}(undef,N,N)\n",
    "    for i in 1:length(A)\n",
    "        A[i] = i\n",
    "    end\n",
    "    A\n",
    "end\n",
    "\n",
    "@time fill_regular(10000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.255586 seconds (191.97 k allocations: 9.586 MiB)\n"
     ]
    }
   ],
   "source": [
    "# shared array\n",
    "function fill_shared(N)\n",
    "    S = SharedMatrix{Int64}(N,N)\n",
    "    @sync @distributed for i in 1:length(S)\n",
    "        S[i] = i\n",
    "    end\n",
    "    S\n",
    "end\n",
    "\n",
    "@time fill_shared(10000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is of course just filling an array.\n",
    "\n",
    "If there were actual calculations it might actually be beneficial to distribute the work across workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel map: `pmap`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we merely wish to apply a function to all all elements in a collection.\n",
    "\n",
    "For those cases, Julia provides the `pmap` (parallel map) function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say, we want to compute the singular values of a bunch of larger matrices in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Array{Float64,2},1}:\n",
       " [0.5330925950927525 0.6901189743520653 … 0.7892543150052973 0.6841751486550747; 0.4006644198286762 0.9343877065522908 … 0.4602352141833119 0.4414737764315051; … ; 0.6904968370508369 0.37327712892225606 … 0.4431469268937638 0.27905227649485354; 0.014027285794929067 0.6055754078740119 … 0.43739563064086373 0.6853907116820122]     \n",
       " [0.031048476648960044 0.6268368964989524 … 0.902933201629911 0.7067020629414484; 0.6026475476055362 0.7585170488568325 … 0.23205133550139223 0.9775525822718905; … ; 0.5701607978571896 0.018943960947579663 … 0.35881276655647865 0.6077587698541034; 0.03668172939872649 0.6263960621814639 … 0.3314359044210011 0.5389375354710877]    \n",
       " [0.03236920217182493 0.9785964767206616 … 0.4716950907689621 0.054239647601908025; 0.42154078489959845 0.6983841185525226 … 0.14612089219948565 0.629129143742065; … ; 0.6352496317270575 0.7612322584853946 … 0.09797189688164054 0.11585836981635111; 0.01818281058431359 0.8547520638949575 … 0.24318843050414918 0.1288815932123566]  \n",
       " [0.8529951739317307 0.3288680409738922 … 0.2931788716386243 0.5496067803097067; 0.8873352484768491 0.3874840980087375 … 0.8927321903518683 0.8945359342524279; … ; 0.9835087201039026 0.7579231065517564 … 0.7469074943673724 0.07669241720225695; 0.1724822615937145 0.4097974013879466 … 0.1418094310184761 0.6313413014688816]         \n",
       " [0.5590161779707097 0.5546439411929827 … 0.16962688460191222 0.6946669993412586; 0.4368866135054088 0.13251914598259518 … 0.9367249858384359 0.004481899104164633; … ; 0.9783086206486615 0.932791836820539 … 0.6989990285892023 0.7468679011586372; 0.13004854140139188 0.5457478304873487 … 0.8596290874316881 0.4859782504349972]      \n",
       " [0.13327740988986392 0.5725469440264377 … 0.31490465774446674 0.38851047157181684; 0.39223635656767586 0.4455726637049633 … 0.40548546332754487 0.8245655890798711; … ; 0.898824194197767 0.5582251751014513 … 0.8726448972148269 0.9820091555091599; 0.3724499319537955 0.5093015941490981 … 0.7924137486311371 0.1557628537787341]      \n",
       " [0.3877713512101606 0.7688369747101003 … 0.9355152532635835 0.9312603263832246; 0.8765098496494861 0.27813028655092387 … 0.08287695181762333 0.9681447983339069; … ; 0.07665930947239241 0.8472911425010861 … 0.21558738836053948 0.5857583089306746; 0.6522900640351097 0.7396059288732668 … 0.6854922164051551 0.07137540567887979]     \n",
       " [0.5291957458552461 0.9622854906576528 … 0.6408935380664056 0.09028896653664531; 0.36632982347452137 0.3238232919234614 … 0.11256382496910966 0.43697099622047686; … ; 0.29846097520375214 0.28231850274691705 … 0.19964890778842537 0.04028831442245284; 0.11014608014979244 0.9510315523129547 … 0.2550597563101993 0.6623461259245549] \n",
       " [0.41012643340496213 0.7379509994380189 … 0.07184929550468122 0.34557094058219096; 0.12553256760110476 0.01938441159059434 … 0.3550360183482779 0.3658929732627223; … ; 0.9777806958908988 0.7180263121076087 … 0.6471708334957056 0.47149830788085834; 0.01809801529536026 0.17493912746586204 … 0.4367270451447356 0.033629844966506894]\n",
       " [0.13968157954135085 0.6192200801670988 … 0.016122821328704795 0.30756969220491315; 0.3408334059744389 0.8153654679123081 … 0.9934518406994213 0.03435742338912151; … ; 0.8267404255190325 0.9013753056844669 … 0.8249411777934643 0.29504367815218524; 0.8264276155125216 0.6963610383392072 … 0.4763539180006586 0.7757839718213582]    "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@everywhere using LinearAlgebra\n",
    "\n",
    "M = Matrix{Float64}[rand(1000,1000) for i = 1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Array{Float64,1},1}:\n",
       " [500.38999979189396, 18.047114079415817, 17.968589089643107, 17.929234702276272, 17.795928015940397, 17.68625956732749, 17.658912450344424, 17.621680020117427, 17.5775461703858, 17.525758691671495  …  0.13622314203750377, 0.12183064545279992, 0.11293871705739549, 0.10556725942289458, 0.0616664621852149, 0.0493667786222552, 0.042913008282710476, 0.029279370022512366, 0.011950032697085118, 0.002202861589712284]\n",
       " [500.03705854249887, 18.257072298874576, 18.10426379181714, 17.906329365437, 17.89273345189213, 17.854281567732208, 17.773330272157242, 17.701269225382635, 17.667580657237966, 17.630105932079797  …  0.12698615318073558, 0.10881042050879301, 0.10707720616652332, 0.10162331876467341, 0.0818138710151222, 0.06312315604153264, 0.05279492542356188, 0.0385352486907368, 0.010441077166236082, 0.003296660342276354]    \n",
       " [500.21486952799467, 18.25385684395223, 18.13222403001239, 18.05784610119117, 17.93415340782225, 17.775940882884292, 17.753003564255835, 17.621446078709702, 17.607628267491, 17.577849092046833  …  0.1278073577915758, 0.11302763278113084, 0.09789888273859003, 0.08252249282453625, 0.07239532069414648, 0.05516336241088615, 0.049572588788247884, 0.045663301080042636, 0.029421433572458362, 0.015102859070409173]   \n",
       " [499.9789709432161, 18.249149489812638, 18.08086878907917, 17.933583396428997, 17.88269683834872, 17.816171807291784, 17.750556797398488, 17.697684570081105, 17.629776024883352, 17.607014603335177  …  0.12665544472784804, 0.11035997983483395, 0.10091544204533143, 0.07848001420874853, 0.07091047842326417, 0.06323490411256652, 0.05659681226090076, 0.054025096809249724, 0.02634907781610816, 0.013961029489126992]\n",
       " [499.9286123759494, 18.180902755081014, 17.93013397230386, 17.909991632928897, 17.784256524999048, 17.71299322728034, 17.67011296916335, 17.617752941380797, 17.597069818337857, 17.558990213260174  …  0.132429687816337, 0.12384534594073808, 0.10197581398843444, 0.09593799895256544, 0.08180257518980187, 0.06672038232771481, 0.060247647229566874, 0.04860280633762884, 0.01893174094462718, 0.007920950292496403]   \n",
       " [499.91561132381065, 18.15576635307906, 18.078156924079885, 18.01376170736406, 17.913145558302038, 17.862154409385152, 17.748090743277043, 17.707296475974037, 17.641071489884364, 17.611713937994708  …  0.132907823914537, 0.1025277326754558, 0.09103590445298845, 0.0895360084779689, 0.07108953700731242, 0.054696803180437896, 0.05015043928304003, 0.03772710309294284, 0.022840517028628316, 0.0023104118201948197] \n",
       " [500.34502960419843, 18.141002415493464, 18.094118639181485, 18.006744560904696, 17.991219886684238, 17.844411655117153, 17.78185178126761, 17.75474533249603, 17.65432428341457, 17.55572787441894  …  0.13656126321286113, 0.12283402388136348, 0.10976468919120701, 0.09091539767496266, 0.08444083309976394, 0.05193449343102289, 0.05119582773355894, 0.0412159811542868, 0.029753503689767726, 0.018218347752059025]  \n",
       " [500.2693874197375, 18.23886883780908, 18.125229586534974, 17.97105090692299, 17.86579032553332, 17.799930634733766, 17.779140522678627, 17.752134491883474, 17.63448979453006, 17.588341787891213  …  0.13905986759560818, 0.1324470173934502, 0.11147463678937965, 0.10605053101031381, 0.10155687262150735, 0.08897233227852326, 0.06254271998698786, 0.0278353062170267, 0.018732145708669615, 0.005663623043451585]    \n",
       " [500.467565074637, 18.07003653018207, 18.0219613808773, 17.952559565705336, 17.826099948646075, 17.766196121480167, 17.742387053986526, 17.664315850988572, 17.603422234498687, 17.53551079813925  …  0.1342694153684542, 0.11249305409643001, 0.10019146640105091, 0.0931671062022522, 0.06083976642252987, 0.046949851095561025, 0.03419373853078325, 0.026191934128236373, 0.012257031576174977, 0.005524681411341926]   \n",
       " [500.0508408741807, 18.12925092437731, 17.89739415197717, 17.83869281587219, 17.803658291568215, 17.763686440072245, 17.672218498138033, 17.623464586448193, 17.608189530346383, 17.48804209935813  …  0.1118330692316103, 0.10868020040881742, 0.09552227876697583, 0.08157658243769525, 0.07035654406913397, 0.05934428191889792, 0.051240803696629714, 0.03955591836481991, 0.021916770333706776, 0.009607493462352294]  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmap(svdvals, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 12:\t12\n",
      "      From worker 13:\t13\n",
      "      From worker 11:\t11\n",
      "      From worker 10:\t10\n",
      "      From worker 12:\t12\n",
      "      From worker 13:\t13\n",
      "      From worker 11:\t11\n",
      "      From worker 10:\t10\n",
      "      From worker 12:\t12\n",
      "      From worker 13:\t13\n"
     ]
    }
   ],
   "source": [
    "# Check that really all of the workers participated\n",
    "pmap(m->begin println(myid()); svdvals(m) end, M);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.873480 seconds (15.32 k allocations: 82.859 MiB, 0.51% gc time)\n",
      "  2.979710 seconds (107 allocations: 82.099 MiB, 0.29% gc time)\n",
      "  2.293630 seconds (1.15 k allocations: 119.984 KiB)\n"
     ]
    }
   ],
   "source": [
    "function svds_loop(M)\n",
    "    svds = Vector{Vector{Float64}}(undef, 10)\n",
    "    for (i, m) in enumerate(M)\n",
    "        svds[i] = svdvals(m)\n",
    "    end\n",
    "    svds\n",
    "end\n",
    "\n",
    "@time svds_loop(M);\n",
    "@time svdvals.(M);\n",
    "@time pmap(svdvals, M);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to choose which?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia's pmap is designed for the case where each function call does a **large amount of work**.\n",
    "\n",
    "In contrast, `@distributed` can handle situations where **each iteration is tiny**, perhaps only summing two numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling things up: THP cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have worked on multiple cores on a single machine, your laptop for example.\n",
    "\n",
    "Processes can live on other machines as well! This allows us to distribute our computation across computer clusters.\n",
    "\n",
    "In principle, the plan of action is the same as in the multi-core case. However, we have to take into account the different memory situation. In particular, **data movement is expensive** and we won't be able to use `SharedArray`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (done) @0x000000000fbfb6b0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmprocs(workers()) # fresh start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating workers on the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding processes on different machines is not much harder than adding them on your local machine. In the following we will take the last example, calculating singular values of a bunch of matrices, and distribute it over multiple computers in our thp network.\n",
    "\n",
    "In Julia, starting worker processes is handled by [ClusterManagers](https://docs.julialang.org/en/stable/manual/parallel-computing/#ClusterManagers-1).\n",
    "\n",
    "* The default one is `LocalManager`. It is automatically used when running `addprocs(i::Integer)` and we have implicitly used it already!\n",
    "* The one we are going to use for the THP cluster is `SSHManager`. It is automatically used when running `addprocs(hostnames::Array)`.\n",
    "\n",
    "Other cluster managers for SLURM, PBS, and others are provided in [ClusterManagers.jl](https://github.com/JuliaParallel/ClusterManagers.jl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle, starting processes on other computers can be done by `addprocs([\"l92\", \"l93\"])`, where `\"l92\"` and `\"l93\"` are hostnames. The only requirement is a **passwordless ssh access** to all specified hosts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Demonstrate in terminal from thp node*\n",
    "\n",
    "```julia\n",
    "using Distributed\n",
    "\n",
    "addprocs([\"l92\", \"l93\"])\n",
    "\n",
    "@everywhere println(gethostname())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also start multiple processes on different machines:\n",
    "```julia\n",
    "addprocs([(\"l92\", 2), (\"l93\", 3)]) # starts 2 workers on l92 and 3 workers on l93\n",
    "\n",
    "# Use :auto to start as many processes as CPUs are available\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `addprocs` expects the julia executable in the same folder as on the master computer (remember: workers are independent Julia processes). It will also try to `cd` to the same folder.\n",
    "\n",
    "In my case this would be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pwd() = \"C:\\\\Users\\\\carsten\\\\Desktop\\\\JuliaWorkshop19\\\\3_Three\"\n",
      "Sys.BINDIR = \"C:\\\\Users\\\\carsten\\\\AppData\\\\Local\\\\Julia-1.2.0\\\\bin\"\n"
     ]
    }
   ],
   "source": [
    "@show pwd();\n",
    "@show Sys.BINDIR;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both folders don't exist in my thp account (those are linux machines!), so I'll have to tell Julia to use different paths.\n",
    "\n",
    "Also, as per thp cluster guidelines one **(!) must (!) run computations on other thp computer with `nice -19` priority setting**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating `nice -19` workers and specifying directories "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from `?addprocs`, `addprocs` takes a bunch of keyword arguments, two of which are of particular importance.\n",
    "\n",
    "* `dir`: working directory of the worker process\n",
    "* `exename`: path to julia executable (potentially augmented with pre-commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(exename = `\u001b[4mnice\u001b[24m \u001b[4m-19\u001b[24m \u001b[4m/home/bauer/bin/julia-1.1.1/bin/julia\u001b[24m \u001b[4m--project=/home/bauer/JuliaWorkshop19\u001b[24m`, dir = \"/home/bauer\")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = (exename=`nice -19 /home/bauer/bin/julia-1.1.1/bin/julia --project=/home/bauer/JuliaWorkshop19`, dir=\"/home/bauer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 17"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs([(\"l92\", :auto)]; params...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l91\n",
      "      From worker 14:\tl92.thp.uni-koeln.de\n",
      "      From worker 17:\tl92.thp.uni-koeln.de\n",
      "      From worker 15:\tl92.thp.uni-koeln.de\n",
      "      From worker 16:\tl92.thp.uni-koeln.de\n"
     ]
    }
   ],
   "source": [
    "@everywhere println(gethostname())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (done) @0x000000001006a570"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmprocs(workers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's get some resources :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Tuple{String,Symbol},1}:\n",
       " (\"l92\", :auto)\n",
       " (\"l93\", :auto)\n",
       " (\"l95\", :auto)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machines = [\"l92\", \"l93\", \"l95\"];\n",
    "\n",
    "procs_per_machine = :auto; # :auto for n = # cpus\n",
    "\n",
    "jobs = [(m,procs_per_machine) for m in machines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12-element Array{Int64,1}:\n",
       " 18\n",
       " 19\n",
       " 20\n",
       " 21\n",
       " 22\n",
       " 23\n",
       " 24\n",
       " 25\n",
       " 26\n",
       " 27\n",
       " 28\n",
       " 29"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs(jobs; params...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l91\n",
      "      From worker 18:\tl93.thp.uni-koeln.de\n",
      "      From worker 22:\tl93.thp.uni-koeln.de\n",
      "      From worker 23:\tl93.thp.uni-koeln.de\n",
      "      From worker 21:\tl93.thp.uni-koeln.de\n",
      "      From worker 20:\tl92.thp.uni-koeln.de\n",
      "      From worker 19:\tl95.thp.uni-koeln.de\n",
      "      From worker 27:\tl92.thp.uni-koeln.de\n",
      "      From worker 29:\tl92.thp.uni-koeln.de\n",
      "      From worker 28:\tl92.thp.uni-koeln.de\n",
      "      From worker 26:\tl95.thp.uni-koeln.de\n",
      "      From worker 24:\tl95.thp.uni-koeln.de\n",
      "      From worker 25:\tl95.thp.uni-koeln.de\n"
     ]
    }
   ],
   "source": [
    "@everywhere println(gethostname())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.930237 seconds (1.28 k allocations: 897.016 KiB)\n"
     ]
    }
   ],
   "source": [
    "@everywhere using LinearAlgebra\n",
    "\n",
    "@time x = pmap(svdvals, M);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed arrays (`DArray`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Github: https://github.com/JuliaParallel/DistributedArrays.jl\n",
    "\n",
    "In a `DArray`, each process has local access to just a chunk of the data, and no two processes share the same chunk. Processes can be on different hosts.\n",
    "\n",
    "Distributed arrays are for example useful if\n",
    "\n",
    "* Expensive calculations should be performed in parallel on parts of the array on different hosts.\n",
    "* The data doesn't fit into the local machines memory (Loading big files in parallel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using DistributedArrays, LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nworkers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element DArray{Array{Float64,2},1,Array{Array{Float64,2},1}}:\n",
       " [0.5330925950927525 0.6901189743520653 … 0.7892543150052973 0.6841751486550747; 0.4006644198286762 0.9343877065522908 … 0.4602352141833119 0.4414737764315051; … ; 0.6904968370508369 0.37327712892225606 … 0.4431469268937638 0.27905227649485354; 0.014027285794929067 0.6055754078740119 … 0.43739563064086373 0.6853907116820122]     \n",
       " [0.031048476648960044 0.6268368964989524 … 0.902933201629911 0.7067020629414484; 0.6026475476055362 0.7585170488568325 … 0.23205133550139223 0.9775525822718905; … ; 0.5701607978571896 0.018943960947579663 … 0.35881276655647865 0.6077587698541034; 0.03668172939872649 0.6263960621814639 … 0.3314359044210011 0.5389375354710877]    \n",
       " [0.03236920217182493 0.9785964767206616 … 0.4716950907689621 0.054239647601908025; 0.42154078489959845 0.6983841185525226 … 0.14612089219948565 0.629129143742065; … ; 0.6352496317270575 0.7612322584853946 … 0.09797189688164054 0.11585836981635111; 0.01818281058431359 0.8547520638949575 … 0.24318843050414918 0.1288815932123566]  \n",
       " [0.8529951739317307 0.3288680409738922 … 0.2931788716386243 0.5496067803097067; 0.8873352484768491 0.3874840980087375 … 0.8927321903518683 0.8945359342524279; … ; 0.9835087201039026 0.7579231065517564 … 0.7469074943673724 0.07669241720225695; 0.1724822615937145 0.4097974013879466 … 0.1418094310184761 0.6313413014688816]         \n",
       " [0.5590161779707097 0.5546439411929827 … 0.16962688460191222 0.6946669993412586; 0.4368866135054088 0.13251914598259518 … 0.9367249858384359 0.004481899104164633; … ; 0.9783086206486615 0.932791836820539 … 0.6989990285892023 0.7468679011586372; 0.13004854140139188 0.5457478304873487 … 0.8596290874316881 0.4859782504349972]      \n",
       " [0.13327740988986392 0.5725469440264377 … 0.31490465774446674 0.38851047157181684; 0.39223635656767586 0.4455726637049633 … 0.40548546332754487 0.8245655890798711; … ; 0.898824194197767 0.5582251751014513 … 0.8726448972148269 0.9820091555091599; 0.3724499319537955 0.5093015941490981 … 0.7924137486311371 0.1557628537787341]      \n",
       " [0.3877713512101606 0.7688369747101003 … 0.9355152532635835 0.9312603263832246; 0.8765098496494861 0.27813028655092387 … 0.08287695181762333 0.9681447983339069; … ; 0.07665930947239241 0.8472911425010861 … 0.21558738836053948 0.5857583089306746; 0.6522900640351097 0.7396059288732668 … 0.6854922164051551 0.07137540567887979]     \n",
       " [0.5291957458552461 0.9622854906576528 … 0.6408935380664056 0.09028896653664531; 0.36632982347452137 0.3238232919234614 … 0.11256382496910966 0.43697099622047686; … ; 0.29846097520375214 0.28231850274691705 … 0.19964890778842537 0.04028831442245284; 0.11014608014979244 0.9510315523129547 … 0.2550597563101993 0.6623461259245549] \n",
       " [0.41012643340496213 0.7379509994380189 … 0.07184929550468122 0.34557094058219096; 0.12553256760110476 0.01938441159059434 … 0.3550360183482779 0.3658929732627223; … ; 0.9777806958908988 0.7180263121076087 … 0.6471708334957056 0.47149830788085834; 0.01809801529536026 0.17493912746586204 … 0.4367270451447356 0.033629844966506894]\n",
       " [0.13968157954135085 0.6192200801670988 … 0.016122821328704795 0.30756969220491315; 0.3408334059744389 0.8153654679123081 … 0.9934518406994213 0.03435742338912151; … ; 0.8267404255190325 0.9013753056844669 … 0.8249411777934643 0.29504367815218524; 0.8264276155125216 0.6963610383392072 … 0.4763539180006586 0.7757839718213582]    "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = distribute(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which workers hold parts of D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Int64,1}:\n",
       " 18\n",
       " 19\n",
       " 20\n",
       " 21\n",
       " 22\n",
       " 23\n",
       " 24\n",
       " 25\n",
       " 26\n",
       " 27"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "procs(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which parts do they hold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0-element Array{Array{Float64,2},1}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "localpart(D) # the master doesn't hold anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "RemoteException",
     "evalue": "On worker 18:\nTypeError: in typeassert, expected Core.SimpleVector, got String\ndeserialize at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:916\nhandle_deserialize at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:856\ndeserialize_fillarray! at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:1019\ndeserialize_array at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:1011\nhandle_deserialize at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:769\ndeserialize_typename at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:731\ndeserialize at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Distributed/src/clusterserialize.jl:68\nhandle_deserialize at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:856\ndeserialize at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:731\nhandle_deserialize at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:775\ndeserialize at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:731\nhandle_deserialize at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:778\ndeserialize_msg at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:731\n#invokelatest#1 at ./essentials.jl:742 [inlined]\ninvokelatest at ./essentials.jl:741 [inlined]\nmessage_handler_loop at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Distributed/src/process_messages.jl:160\nprocess_tcp_streams at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Distributed/src/process_messages.jl:117\n#105 at ./task.jl:259",
     "output_type": "error",
     "traceback": [
      "On worker 18:\nTypeError: in typeassert, expected Core.SimpleVector, got String\ndeserialize at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:916\nhandle_deserialize at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:856\ndeserialize_fillarray! at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:1019\ndeserialize_array at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:1011\nhandle_deserialize at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:769\ndeserialize_typename at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:731\ndeserialize at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Distributed/src/clusterserialize.jl:68\nhandle_deserialize at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:856\ndeserialize at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:731\nhandle_deserialize at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:775\ndeserialize at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:731\nhandle_deserialize at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:778\ndeserialize_msg at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Serialization/src/Serialization.jl:731\n#invokelatest#1 at ./essentials.jl:742 [inlined]\ninvokelatest at ./essentials.jl:741 [inlined]\nmessage_handler_loop at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Distributed/src/process_messages.jl:160\nprocess_tcp_streams at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Distributed/src/process_messages.jl:117\n#105 at ./task.jl:259",
      "",
      "Stacktrace:",
      " [1] #remotecall_fetch#149 at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Distributed\\src\\remotecall.jl:379 [inlined]",
      " [2] remotecall_fetch(::Function, ::Distributed.Worker) at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Distributed\\src\\remotecall.jl:371",
      " [3] #remotecall_fetch#152(::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::typeof(remotecall_fetch), ::Function, ::Int64) at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Distributed\\src\\remotecall.jl:406",
      " [4] remotecall_fetch(::Function, ::Int64) at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.2\\Distributed\\src\\remotecall.jl:406",
      " [5] top-level scope at In[97]:3"
     ]
    }
   ],
   "source": [
    "# Which parts do they hold?\n",
    "for p in workers()\n",
    "    display(@fetchfrom p localpart(D))\n",
    "    display(@fetchfrom p DistributedArrays.localindices(D)) # DistributedArrays. necessary because of SharedArrays above\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time Msquared = map(svdvals, M);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time Dsquared = map(svdvals, D);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time Psquared = pmap(svdvals, M);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Msquared ≈ Dsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dsquared ≈ Psquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But remember, for small operations the data movement can (and will) exceed the benefit of parallelizing the computation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime map(sum, M);\n",
    "@btime map(sum, D);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A demonstration of distributed arrays: [Parallel loading and processing of large files](https://www.youtube.com/watch?v=euZkvgx0fG8&t=3925s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop worker processes!\n",
    "rmprocs(workers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Parallel Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the value of $\\pi$ through parallel direct Monte Carlo.\n",
    "\n",
    "A unit circle is inscribed inside a unit square with side length 2 (from -1 to 1). The area of the circle is $\\pi$, the area of the square is 4, and the ratio is $\\pi/4$. This means that, if you throw $N$ darts randomly at the square, approximately $M=N\\pi/4$ of those darts will land inside the unit circle.\n",
    "\n",
    "Throw darts randomly at a unit square and count how many of them ($M$) landed inside of a unit circle. Approximate $\\pi \\approx 4M/N$. Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (done) @0x000000004b120e70"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmprocs(workers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 21:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for DataStructures [864edb3b-99cc-5e75-8d2d-829cb0a9cfe8]\n",
      "      From worker 21:\t│   exception = ArgumentError: Invalid checksum in cache file /home/bauer/.julia/compiled/v1.1/DataStructures/xKiwJ.ji.\n",
      "      From worker 21:\t└ @ Base loading.jl:969\n",
      "      From worker 23:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for DataStructures [864edb3b-99cc-5e75-8d2d-829cb0a9cfe8]\n",
      "      From worker 23:\t│   exception = Required dependency OrderedCollections [bac558e1-5e72-5ebc-8fee-abe8a469f55d] failed to load from a cache file.\n",
      "      From worker 23:\t└ @ Base loading.jl:969\n",
      "      From worker 22:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for DataStructures [864edb3b-99cc-5e75-8d2d-829cb0a9cfe8]\n",
      "      From worker 22:\t│   exception = Required dependency OrderedCollections [bac558e1-5e72-5ebc-8fee-abe8a469f55d] failed to load from a cache file.\n",
      "      From worker 22:\t└ @ Base loading.jl:969\n",
      "      From worker 18:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for DataStructures [864edb3b-99cc-5e75-8d2d-829cb0a9cfe8]\n",
      "      From worker 18:\t│   exception = Required dependency OrderedCollections [bac558e1-5e72-5ebc-8fee-abe8a469f55d] failed to load from a cache file.\n",
      "      From worker 18:\t└ @ Base loading.jl:969\n",
      "      From worker 19:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for Tokenize [0796e94c-ce3b-5d07-9a54-7f471281c624]\n",
      "      From worker 19:\t│   exception = ArgumentError: Invalid checksum in cache file /home/bauer/.julia/compiled/v1.1/Tokenize/7Oi97.ji.\n",
      "      From worker 19:\t└ @ Base loading.jl:969\n",
      "      From worker 23:\t┌ Warning: Module Tokenize with build ID 1532636153165493 is missing from the cache.\n",
      "      From worker 23:\t│ This may mean Tokenize [0796e94c-ce3b-5d07-9a54-7f471281c624] does not support precompilation but is imported by a module that does.\n",
      "      From worker 23:\t└ @ Base loading.jl:947\n",
      "      From worker 21:\t┌ Warning: Module Tokenize with build ID 1532635963346062 is missing from the cache.\n",
      "      From worker 21:\t│ This may mean Tokenize [0796e94c-ce3b-5d07-9a54-7f471281c624] does not support precompilation but is imported by a module that does.\n",
      "      From worker 21:\t└ @ Base loading.jl:947\n",
      "      From worker 22:\t┌ Warning: Module Tokenize with build ID 1532636206492028 is missing from the cache.\n",
      "      From worker 22:\t│ This may mean Tokenize [0796e94c-ce3b-5d07-9a54-7f471281c624] does not support precompilation but is imported by a module that does.\n",
      "      From worker 22:\t└ @ Base loading.jl:947\n",
      "      From worker 18:\t┌ Warning: Module Tokenize with build ID 1532636206492028 is missing from the cache.\n",
      "      From worker 18:\t│ This may mean Tokenize [0796e94c-ce3b-5d07-9a54-7f471281c624] does not support precompilation but is imported by a module that does.\n",
      "      From worker 18:\t└ @ Base loading.jl:947\n",
      "      From worker 24:\t┌ Warning: Module Tokenize with build ID 1375879800816808 is missing from the cache.\n",
      "      From worker 24:\t│ This may mean Tokenize [0796e94c-ce3b-5d07-9a54-7f471281c624] does not support precompilation but is imported by a module that does.\n",
      "      From worker 24:\t└ @ Base loading.jl:947\n",
      "      From worker 26:\t┌ Warning: Module Tokenize with build ID 1375879784804134 is missing from the cache.\n",
      "      From worker 26:\t│ This may mean Tokenize [0796e94c-ce3b-5d07-9a54-7f471281c624] does not support precompilation but is imported by a module that does.\n",
      "      From worker 26:\t└ @ Base loading.jl:947\n",
      "      From worker 29:\t┌ Warning: Module Tokenize with build ID 1532636206492028 is missing from the cache.\n",
      "      From worker 29:\t│ This may mean Tokenize [0796e94c-ce3b-5d07-9a54-7f471281c624] does not support precompilation but is imported by a module that does.\n",
      "      From worker 29:\t└ @ Base loading.jl:947\n",
      "      From worker 28:\t┌ Warning: Module Tokenize with build ID 1532636206492028 is missing from the cache.\n",
      "      From worker 28:\t│ This may mean Tokenize [0796e94c-ce3b-5d07-9a54-7f471281c624] does not support precompilation but is imported by a module that does.\n",
      "      From worker 28:\t└ @ Base loading.jl:947\n",
      "      From worker 27:\t┌ Warning: Module Tokenize with build ID 1532636206492028 is missing from the cache.\n",
      "      From worker 27:\t│ This may mean Tokenize [0796e94c-ce3b-5d07-9a54-7f471281c624] does not support precompilation but is imported by a module that does.\n",
      "      From worker 27:\t└ @ Base loading.jl:947\n",
      "      From worker 20:\t┌ Warning: Module Tokenize with build ID 1375879800816808 is missing from the cache.\n",
      "      From worker 20:\t│ This may mean Tokenize [0796e94c-ce3b-5d07-9a54-7f471281c624] does not support precompilation but is imported by a module that does.\n",
      "      From worker 20:\t└ @ Base loading.jl:947\n",
      "      From worker 19:\t┌ Warning: Module Tokenize with build ID 1375881731860223 is missing from the cache.\n",
      "      From worker 19:\t│ This may mean Tokenize [0796e94c-ce3b-5d07-9a54-7f471281c624] does not support precompilation but is imported by a module that does.\n",
      "      From worker 19:\t└ @ Base loading.jl:947\n",
      "      From worker 21:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for MacroTools [1914dd2f-81c6-5fcd-8719-6d5c9610ff09]\n",
      "      From worker 21:\t│   exception = ArgumentError: Invalid checksum in cache file /home/bauer/.julia/compiled/v1.1/MacroTools/38lnR.ji.\n",
      "      From worker 21:\t└ @ Base loading.jl:969\n",
      "      From worker 22:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for MacroTools [1914dd2f-81c6-5fcd-8719-6d5c9610ff09]\n",
      "      From worker 22:\t│   exception = ArgumentError: Invalid checksum in cache file /home/bauer/.julia/compiled/v1.1/MacroTools/38lnR.ji.\n",
      "      From worker 22:\t└ @ Base loading.jl:969\n",
      "      From worker 23:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for MacroTools [1914dd2f-81c6-5fcd-8719-6d5c9610ff09]\n",
      "      From worker 23:\t│   exception = Required dependency Tokenize [0796e94c-ce3b-5d07-9a54-7f471281c624] failed to load from a cache file.\n",
      "      From worker 23:\t└ @ Base loading.jl:969\n",
      "      From worker 18:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for MacroTools [1914dd2f-81c6-5fcd-8719-6d5c9610ff09]\n",
      "      From worker 18:\t│   exception = Required dependency Tokenize [0796e94c-ce3b-5d07-9a54-7f471281c624] failed to load from a cache file.\n",
      "      From worker 18:\t└ @ Base loading.jl:969\n",
      "      From worker 26:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for MacroTools [1914dd2f-81c6-5fcd-8719-6d5c9610ff09]\n",
      "      From worker 26:\t│   exception = Required dependency Tokenize [0796e94c-ce3b-5d07-9a54-7f471281c624] failed to load from a cache file.\n",
      "      From worker 26:\t└ @ Base loading.jl:969\n",
      "      From worker 24:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for MacroTools [1914dd2f-81c6-5fcd-8719-6d5c9610ff09]\n",
      "      From worker 24:\t│   exception = Required dependency Tokenize [0796e94c-ce3b-5d07-9a54-7f471281c624] failed to load from a cache file.\n",
      "      From worker 24:\t└ @ Base loading.jl:969\n",
      "      From worker 25:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for MacroTools [1914dd2f-81c6-5fcd-8719-6d5c9610ff09]\n",
      "      From worker 25:\t│   exception = Required dependency DataStructures [864edb3b-99cc-5e75-8d2d-829cb0a9cfe8] failed to load from a cache file.\n",
      "      From worker 25:\t└ @ Base loading.jl:969\n",
      "      From worker 19:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for MacroTools [1914dd2f-81c6-5fcd-8719-6d5c9610ff09]\n",
      "      From worker 19:\t│   exception = Required dependency DataStructures [864edb3b-99cc-5e75-8d2d-829cb0a9cfe8] failed to load from a cache file.\n",
      "      From worker 19:\t└ @ Base loading.jl:969\n",
      "      From worker 27:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for MacroTools [1914dd2f-81c6-5fcd-8719-6d5c9610ff09]\n",
      "      From worker 27:\t│   exception = Required dependency Tokenize [0796e94c-ce3b-5d07-9a54-7f471281c624] failed to load from a cache file.\n",
      "      From worker 27:\t└ @ Base loading.jl:969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 20:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for MacroTools [1914dd2f-81c6-5fcd-8719-6d5c9610ff09]\n",
      "      From worker 20:\t│   exception = Required dependency Tokenize [0796e94c-ce3b-5d07-9a54-7f471281c624] failed to load from a cache file.\n",
      "      From worker 20:\t└ @ Base loading.jl:969\n",
      "      From worker 28:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for MacroTools [1914dd2f-81c6-5fcd-8719-6d5c9610ff09]\n",
      "      From worker 28:\t│   exception = Required dependency Tokenize [0796e94c-ce3b-5d07-9a54-7f471281c624] failed to load from a cache file.\n",
      "      From worker 28:\t└ @ Base loading.jl:969\n",
      "      From worker 29:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for MacroTools [1914dd2f-81c6-5fcd-8719-6d5c9610ff09]\n",
      "      From worker 29:\t│   exception = Required dependency Tokenize [0796e94c-ce3b-5d07-9a54-7f471281c624] failed to load from a cache file.\n",
      "      From worker 29:\t└ @ Base loading.jl:969\n",
      "      From worker 28:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for CSTParser [00ebfdb7-1f24-5e51-bd34-a7502290713f]\n",
      "      From worker 28:\t│   exception = ArgumentError: Invalid checksum in cache file /home/bauer/.julia/compiled/v1.1/CSTParser/R4aS6.ji.\n",
      "      From worker 28:\t└ @ Base loading.jl:969\n",
      "      From worker 22:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PyCall [438e738f-606a-5dbb-bf0a-cddfbfd45ab0]\n",
      "      From worker 22:\t│   exception = Required dependency CSTParser [00ebfdb7-1f24-5e51-bd34-a7502290713f] failed to load from a cache file.\n",
      "      From worker 22:\t└ @ Base loading.jl:969\n",
      "      From worker 21:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PyCall [438e738f-606a-5dbb-bf0a-cddfbfd45ab0]\n",
      "      From worker 21:\t│   exception = Required dependency CSTParser [00ebfdb7-1f24-5e51-bd34-a7502290713f] failed to load from a cache file.\n",
      "      From worker 21:\t└ @ Base loading.jl:969\n",
      "      From worker 23:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PyCall [438e738f-606a-5dbb-bf0a-cddfbfd45ab0]\n",
      "      From worker 23:\t│   exception = Required dependency CSTParser [00ebfdb7-1f24-5e51-bd34-a7502290713f] failed to load from a cache file.\n",
      "      From worker 23:\t└ @ Base loading.jl:969\n",
      "      From worker 18:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PyCall [438e738f-606a-5dbb-bf0a-cddfbfd45ab0]\n",
      "      From worker 18:\t│   exception = Required dependency CSTParser [00ebfdb7-1f24-5e51-bd34-a7502290713f] failed to load from a cache file.\n",
      "      From worker 18:\t└ @ Base loading.jl:969\n",
      "      From worker 26:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PyCall [438e738f-606a-5dbb-bf0a-cddfbfd45ab0]\n",
      "      From worker 26:\t│   exception = ArgumentError: Invalid checksum in cache file /home/bauer/.julia/compiled/v1.1/PyCall/GkzkC.ji.\n",
      "      From worker 26:\t└ @ Base loading.jl:969\n",
      "      From worker 24:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PyCall [438e738f-606a-5dbb-bf0a-cddfbfd45ab0]\n",
      "      From worker 24:\t│   exception = Required dependency CSTParser [00ebfdb7-1f24-5e51-bd34-a7502290713f] failed to load from a cache file.\n",
      "      From worker 24:\t└ @ Base loading.jl:969\n",
      "      From worker 25:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PyCall [438e738f-606a-5dbb-bf0a-cddfbfd45ab0]\n",
      "      From worker 25:\t│   exception = Required dependency CSTParser [00ebfdb7-1f24-5e51-bd34-a7502290713f] failed to load from a cache file.\n",
      "      From worker 25:\t└ @ Base loading.jl:969\n",
      "      From worker 19:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PyCall [438e738f-606a-5dbb-bf0a-cddfbfd45ab0]\n",
      "      From worker 19:\t│   exception = Required dependency CSTParser [00ebfdb7-1f24-5e51-bd34-a7502290713f] failed to load from a cache file.\n",
      "      From worker 19:\t└ @ Base loading.jl:969\n",
      "      From worker 27:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PyCall [438e738f-606a-5dbb-bf0a-cddfbfd45ab0]\n",
      "      From worker 27:\t│   exception = Required dependency CSTParser [00ebfdb7-1f24-5e51-bd34-a7502290713f] failed to load from a cache file.\n",
      "      From worker 27:\t└ @ Base loading.jl:969\n",
      "      From worker 20:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PyCall [438e738f-606a-5dbb-bf0a-cddfbfd45ab0]\n",
      "      From worker 20:\t│   exception = Invalid input in module list: expected REPL.\n",
      "      From worker 20:\t└ @ Base loading.jl:969\n",
      "      From worker 22:\t┌ Warning: Module FixedPointNumbers with build ID 1532673877942022 is missing from the cache.\n",
      "      From worker 22:\t│ This may mean FixedPointNumbers [53c48c17-4a7d-5ca2-90c5-79b7896eea93] does not support precompilation but is imported by a module that does.\n",
      "      From worker 22:\t└ @ Base loading.jl:947\n",
      "      From worker 21:\t┌ Warning: Module FixedPointNumbers with build ID 1532673988970671 is missing from the cache.\n",
      "      From worker 21:\t│ This may mean FixedPointNumbers [53c48c17-4a7d-5ca2-90c5-79b7896eea93] does not support precompilation but is imported by a module that does.\n",
      "      From worker 21:\t└ @ Base loading.jl:947\n",
      "      From worker 18:\t┌ Warning: Module FixedPointNumbers with build ID 1532674442505648 is missing from the cache.\n",
      "      From worker 18:\t│ This may mean FixedPointNumbers [53c48c17-4a7d-5ca2-90c5-79b7896eea93] does not support precompilation but is imported by a module that does.\n",
      "      From worker 18:\t└ @ Base loading.jl:947\n",
      "      From worker 18:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for Colors [5ae59095-9a9b-59fe-a467-6f913c188581]\n",
      "      From worker 18:\t│   exception = Required dependency FixedPointNumbers [53c48c17-4a7d-5ca2-90c5-79b7896eea93] failed to load from a cache file.\n",
      "      From worker 18:\t└ @ Base loading.jl:969\n",
      "      From worker 22:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for Colors [5ae59095-9a9b-59fe-a467-6f913c188581]\n",
      "      From worker 22:\t│   exception = Required dependency FixedPointNumbers [53c48c17-4a7d-5ca2-90c5-79b7896eea93] failed to load from a cache file.\n",
      "      From worker 22:\t└ @ Base loading.jl:969\n",
      "      From worker 21:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for Colors [5ae59095-9a9b-59fe-a467-6f913c188581]\n",
      "      From worker 21:\t│   exception = Required dependency FixedPointNumbers [53c48c17-4a7d-5ca2-90c5-79b7896eea93] failed to load from a cache file.\n",
      "      From worker 21:\t└ @ Base loading.jl:969\n",
      "      From worker 18:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PyPlot [d330b81b-6aea-500a-939a-2ce795aea3ee]\n",
      "      From worker 18:\t│   exception = ArgumentError: Invalid checksum in cache file /home/bauer/.julia/compiled/v1.1/PyPlot/oatAj.ji.\n",
      "      From worker 18:\t└ @ Base loading.jl:969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PyPlot [d330b81b-6aea-500a-939a-2ce795aea3ee]\n",
      "│   exception = Required dependency LaTeXStrings [b964fa9f-0449-5b57-a5c2-d3ea65f4040f] failed to load from a cache file.\n",
      "└ @ Base loading.jl:969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 18:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PyPlot [d330b81b-6aea-500a-939a-2ce795aea3ee]\n",
      "      From worker 18:\t│   exception = Required dependency LaTeXStrings [b964fa9f-0449-5b57-a5c2-d3ea65f4040f] failed to load from a cache file.\n",
      "      From worker 18:\t└ @ Base loading.jl:969\n",
      "      From worker 18:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PyPlot [d330b81b-6aea-500a-939a-2ce795aea3ee]\n",
      "      From worker 18:\t│   exception = Required dependency LaTeXStrings [b964fa9f-0449-5b57-a5c2-d3ea65f4040f] failed to load from a cache file.\n",
      "      From worker 18:\t└ @ Base loading.jl:969\n",
      "      From worker 19:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PyPlot [d330b81b-6aea-500a-939a-2ce795aea3ee]\n",
      "      From worker 19:\t│   exception = Required dependency LaTeXStrings [b964fa9f-0449-5b57-a5c2-d3ea65f4040f] failed to load from a cache file.\n",
      "      From worker 19:\t└ @ Base loading.jl:969\n",
      "      From worker 19:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PyPlot [d330b81b-6aea-500a-939a-2ce795aea3ee]\n",
      "      From worker 19:\t│   exception = Required dependency ColorTypes [3da002f7-5984-5a60-b8a6-cbb66c0b333f] failed to load from a cache file.\n",
      "      From worker 19:\t└ @ Base loading.jl:969\n",
      "      From worker 19:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PyPlot [d330b81b-6aea-500a-939a-2ce795aea3ee]\n",
      "      From worker 19:\t│   exception = Required dependency ColorTypes [3da002f7-5984-5a60-b8a6-cbb66c0b333f] failed to load from a cache file.\n",
      "      From worker 19:\t└ @ Base loading.jl:969\n",
      "      From worker 20:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for Colors [5ae59095-9a9b-59fe-a467-6f913c188581]\n",
      "      From worker 20:\t│   exception = Required dependency ColorTypes [3da002f7-5984-5a60-b8a6-cbb66c0b333f] failed to load from a cache file.\n",
      "      From worker 20:\t└ @ Base loading.jl:969\n",
      "      From worker 29:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for Colors [5ae59095-9a9b-59fe-a467-6f913c188581]\n",
      "      From worker 29:\t│   exception = Required dependency ColorTypes [3da002f7-5984-5a60-b8a6-cbb66c0b333f] failed to load from a cache file.\n",
      "      From worker 29:\t└ @ Base loading.jl:969\n",
      "      From worker 28:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for Colors [5ae59095-9a9b-59fe-a467-6f913c188581]\n",
      "      From worker 28:\t│   exception = Required dependency ColorTypes [3da002f7-5984-5a60-b8a6-cbb66c0b333f] failed to load from a cache file.\n",
      "      From worker 28:\t└ @ Base loading.jl:969\n",
      "      From worker 19:\t┌ Warning: Replacing module `CSTParser`\n",
      "      From worker 19:\t└ @ Base loading.jl:878\n",
      "      From worker 19:\t┌ Warning: Replacing module `CSTParser`\n",
      "      From worker 19:\t└ @ Base loading.jl:878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PyPlot [d330b81b-6aea-500a-939a-2ce795aea3ee]\n",
      "│   exception = Required dependency ColorTypes [3da002f7-5984-5a60-b8a6-cbb66c0b333f] failed to load from a cache file.\n",
      "└ @ Base loading.jl:969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 20:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PyPlot [d330b81b-6aea-500a-939a-2ce795aea3ee]\n",
      "      From worker 20:\t│   exception = Required dependency ColorTypes [3da002f7-5984-5a60-b8a6-cbb66c0b333f] failed to load from a cache file.\n",
      "      From worker 20:\t└ @ Base loading.jl:969\n",
      "      From worker 20:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PyPlot [d330b81b-6aea-500a-939a-2ce795aea3ee]\n",
      "      From worker 20:\t│   exception = Required dependency CSTParser [00ebfdb7-1f24-5e51-bd34-a7502290713f] failed to load from a cache file.\n",
      "      From worker 20:\t└ @ Base loading.jl:969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Replacing module `CSTParser`\n",
      "└ @ Base loading.jl:878\n",
      "┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PyPlot [d330b81b-6aea-500a-939a-2ce795aea3ee]\n",
      "│   exception = Required dependency ColorTypes [3da002f7-5984-5a60-b8a6-cbb66c0b333f] failed to load from a cache file.\n",
      "└ @ Base loading.jl:969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 18:\t┌ Warning: No working GUI backend found for matplotlib\n",
      "      From worker 18:\t└ @ PyPlot ~/.julia/packages/PyPlot/cdCMF/src/init.jl:155\n",
      "      From worker 18:\t┌ Warning: No working GUI backend found for matplotlib\n",
      "      From worker 18:\t└ @ PyPlot ~/.julia/packages/PyPlot/cdCMF/src/init.jl:155\n",
      "      From worker 20:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PyPlot [d330b81b-6aea-500a-939a-2ce795aea3ee]\n",
      "      From worker 20:\t│   exception = Required dependency Colors [5ae59095-9a9b-59fe-a467-6f913c188581] failed to load from a cache file.\n",
      "      From worker 20:\t└ @ Base loading.jl:969\n",
      "      From worker 18:\t┌ Warning: No working GUI backend found for matplotlib\n",
      "      From worker 18:\t└ @ PyPlot ~/.julia/packages/PyPlot/cdCMF/src/init.jl:155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: No working GUI backend found for matplotlib\n",
      "└ @ PyPlot ~/.julia/packages/PyPlot/cdCMF/src/init.jl:155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 20:\t┌ Warning: Replacing module `CSTParser`\n",
      "      From worker 20:\t└ @ Base loading.jl:878\n",
      "      From worker 20:\t┌ Warning: Replacing module `CSTParser`\n",
      "      From worker 20:\t└ @ Base loading.jl:878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Replacing module `CSTParser`\n",
      "└ @ Base loading.jl:878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 20:\t┌ Warning: Replacing module `CSTParser`\n",
      "      From worker 20:\t└ @ Base loading.jl:878\n",
      "      From worker 19:\t┌ Warning: No working GUI backend found for matplotlib\n",
      "      From worker 19:\t└ @ PyPlot ~/.julia/packages/PyPlot/cdCMF/src/init.jl:155\n",
      "      From worker 19:\t┌ Warning: No working GUI backend found for matplotlib\n",
      "      From worker 19:\t└ @ PyPlot ~/.julia/packages/PyPlot/cdCMF/src/init.jl:155\n",
      "      From worker 19:\t┌ Warning: No working GUI backend found for matplotlib\n",
      "      From worker 19:\t└ @ PyPlot ~/.julia/packages/PyPlot/cdCMF/src/init.jl:155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: No working GUI backend found for matplotlib\n",
      "└ @ PyPlot ~/.julia/packages/PyPlot/cdCMF/src/init.jl:155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 24:\t┌ Warning: Module ColorTypes with build ID 1536768177902088 is missing from the cache.\n",
      "      From worker 24:\t│ This may mean ColorTypes [3da002f7-5984-5a60-b8a6-cbb66c0b333f] does not support precompilation but is imported by a module that does.\n",
      "      From worker 24:\t└ @ Base loading.jl:947\n",
      "      From worker 25:\t┌ Warning: Module ColorTypes with build ID 1536768177902088 is missing from the cache.\n",
      "      From worker 25:\t│ This may mean ColorTypes [3da002f7-5984-5a60-b8a6-cbb66c0b333f] does not support precompilation but is imported by a module that does.\n",
      "      From worker 25:\t└ @ Base loading.jl:947\n",
      "      From worker 20:\t┌ Warning: No working GUI backend found for matplotlib\n",
      "      From worker 20:\t└ @ PyPlot ~/.julia/packages/PyPlot/cdCMF/src/init.jl:155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: No working GUI backend found for matplotlib\n",
      "└ @ PyPlot ~/.julia/packages/PyPlot/cdCMF/src/init.jl:155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 20:\t┌ Warning: No working GUI backend found for matplotlib\n",
      "      From worker 20:\t└ @ PyPlot ~/.julia/packages/PyPlot/cdCMF/src/init.jl:155\n",
      "      From worker 20:\t┌ Warning: No working GUI backend found for matplotlib\n",
      "      From worker 20:\t└ @ PyPlot ~/.julia/packages/PyPlot/cdCMF/src/init.jl:155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Distributions [31c24e10-a181-5473-b8eb-7969acd0382f]\n",
      "└ @ Base loading.jl:1242\n",
      "┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.\n",
      "│   caller = lstirling_asym(::BigFloat) at misc.jl:56\n",
      "└ @ StatsFuns C:\\Users\\carsten\\.julia\\packages\\StatsFuns\\2QE7p\\src\\misc.jl:56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 18:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for StatsBase [2913bbd2-ae8a-5f71-8c99-4fb6c76f3a91]\n",
      "      From worker 18:\t│   exception = Required dependency SortingAlgorithms [a2af1166-a08f-5f64-846c-94a0d3cef48c] failed to load from a cache file.\n",
      "      From worker 18:\t└ @ Base loading.jl:969\n",
      "      From worker 22:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for StatsBase [2913bbd2-ae8a-5f71-8c99-4fb6c76f3a91]\n",
      "      From worker 22:\t│   exception = Required dependency SortingAlgorithms [a2af1166-a08f-5f64-846c-94a0d3cef48c] failed to load from a cache file.\n",
      "      From worker 22:\t└ @ Base loading.jl:969\n",
      "      From worker 21:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for StatsBase [2913bbd2-ae8a-5f71-8c99-4fb6c76f3a91]\n",
      "      From worker 21:\t│   exception = Required dependency SortingAlgorithms [a2af1166-a08f-5f64-846c-94a0d3cef48c] failed to load from a cache file.\n",
      "      From worker 21:\t└ @ Base loading.jl:969\n",
      "      From worker 23:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for StatsBase [2913bbd2-ae8a-5f71-8c99-4fb6c76f3a91]\n",
      "      From worker 23:\t│   exception = Required dependency SortingAlgorithms [a2af1166-a08f-5f64-846c-94a0d3cef48c] failed to load from a cache file.\n",
      "      From worker 23:\t└ @ Base loading.jl:969\n",
      "      From worker 24:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for StatsBase [2913bbd2-ae8a-5f71-8c99-4fb6c76f3a91]\n",
      "      From worker 24:\t│   exception = Required dependency SortingAlgorithms [a2af1166-a08f-5f64-846c-94a0d3cef48c] failed to load from a cache file.\n",
      "      From worker 24:\t└ @ Base loading.jl:969\n",
      "      From worker 26:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for StatsBase [2913bbd2-ae8a-5f71-8c99-4fb6c76f3a91]\n",
      "      From worker 26:\t│   exception = Required dependency SortingAlgorithms [a2af1166-a08f-5f64-846c-94a0d3cef48c] failed to load from a cache file.\n",
      "      From worker 26:\t└ @ Base loading.jl:969\n",
      "      From worker 25:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for StatsBase [2913bbd2-ae8a-5f71-8c99-4fb6c76f3a91]\n",
      "      From worker 25:\t│   exception = Required dependency SortingAlgorithms [a2af1166-a08f-5f64-846c-94a0d3cef48c] failed to load from a cache file.\n",
      "      From worker 25:\t└ @ Base loading.jl:969\n",
      "      From worker 19:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for StatsBase [2913bbd2-ae8a-5f71-8c99-4fb6c76f3a91]\n",
      "      From worker 19:\t│   exception = Required dependency SortingAlgorithms [a2af1166-a08f-5f64-846c-94a0d3cef48c] failed to load from a cache file.\n",
      "      From worker 19:\t└ @ Base loading.jl:969\n",
      "      From worker 29:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for StatsBase [2913bbd2-ae8a-5f71-8c99-4fb6c76f3a91]\n",
      "      From worker 29:\t│   exception = Required dependency SortingAlgorithms [a2af1166-a08f-5f64-846c-94a0d3cef48c] failed to load from a cache file.\n",
      "      From worker 29:\t└ @ Base loading.jl:969\n",
      "      From worker 28:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for StatsBase [2913bbd2-ae8a-5f71-8c99-4fb6c76f3a91]\n",
      "      From worker 28:\t│   exception = Required dependency SortingAlgorithms [a2af1166-a08f-5f64-846c-94a0d3cef48c] failed to load from a cache file.\n",
      "      From worker 28:\t└ @ Base loading.jl:969\n",
      "      From worker 27:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for StatsBase [2913bbd2-ae8a-5f71-8c99-4fb6c76f3a91]\n",
      "      From worker 27:\t│   exception = Required dependency SortingAlgorithms [a2af1166-a08f-5f64-846c-94a0d3cef48c] failed to load from a cache file.\n",
      "      From worker 27:\t└ @ Base loading.jl:969\n",
      "      From worker 18:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PDMats [90014a1f-27ba-587c-ab20-58faa44d9150]\n",
      "      From worker 18:\t│   exception = Required dependency Arpack [7d9fca2a-8960-54d3-9f78-7d1dccf2cb97] failed to load from a cache file.\n",
      "      From worker 18:\t└ @ Base loading.jl:969\n",
      "      From worker 22:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PDMats [90014a1f-27ba-587c-ab20-58faa44d9150]\n",
      "      From worker 22:\t│   exception = Required dependency Arpack [7d9fca2a-8960-54d3-9f78-7d1dccf2cb97] failed to load from a cache file.\n",
      "      From worker 22:\t└ @ Base loading.jl:969\n",
      "      From worker 21:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PDMats [90014a1f-27ba-587c-ab20-58faa44d9150]\n",
      "      From worker 21:\t│   exception = Required dependency Arpack [7d9fca2a-8960-54d3-9f78-7d1dccf2cb97] failed to load from a cache file.\n",
      "      From worker 21:\t└ @ Base loading.jl:969\n",
      "      From worker 26:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for PDMats [90014a1f-27ba-587c-ab20-58faa44d9150]\n",
      "      From worker 26:\t│   exception = Required dependency Arpack [7d9fca2a-8960-54d3-9f78-7d1dccf2cb97] failed to load from a cache file.\n",
      "      From worker 26:\t└ @ Base loading.jl:969\n",
      "      From worker 23:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for StatsFuns [4c63d2b9-4356-54db-8cca-17b64c39e42c]\n",
      "      From worker 23:\t│   exception = Required dependency Rmath [79098fc4-a85e-5d69-aa6a-4863f24498fa] failed to load from a cache file.\n",
      "      From worker 23:\t└ @ Base loading.jl:969\n",
      "      From worker 21:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for StatsFuns [4c63d2b9-4356-54db-8cca-17b64c39e42c]\n",
      "      From worker 21:\t│   exception = ArgumentError: Invalid checksum in cache file /home/bauer/.julia/compiled/v1.1/StatsFuns/530lR.ji.\n",
      "      From worker 21:\t└ @ Base loading.jl:969\n",
      "      From worker 22:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for StatsFuns [4c63d2b9-4356-54db-8cca-17b64c39e42c]\n",
      "      From worker 22:\t│   exception = Required dependency Rmath [79098fc4-a85e-5d69-aa6a-4863f24498fa] failed to load from a cache file.\n",
      "      From worker 22:\t└ @ Base loading.jl:969\n",
      "      From worker 18:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for StatsFuns [4c63d2b9-4356-54db-8cca-17b64c39e42c]\n",
      "      From worker 18:\t│   exception = ArgumentError: Invalid checksum in cache file /home/bauer/.julia/compiled/v1.1/StatsFuns/530lR.ji.\n",
      "      From worker 18:\t└ @ Base loading.jl:969\n",
      "      From worker 24:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for StatsFuns [4c63d2b9-4356-54db-8cca-17b64c39e42c]\n",
      "      From worker 24:\t│   exception = Required dependency Rmath [79098fc4-a85e-5d69-aa6a-4863f24498fa] failed to load from a cache file.\n",
      "      From worker 24:\t└ @ Base loading.jl:969\n",
      "      From worker 25:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for StatsFuns [4c63d2b9-4356-54db-8cca-17b64c39e42c]\n",
      "      From worker 25:\t│   exception = Required dependency Rmath [79098fc4-a85e-5d69-aa6a-4863f24498fa] failed to load from a cache file.\n",
      "      From worker 25:\t└ @ Base loading.jl:969\n",
      "      From worker 19:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for StatsFuns [4c63d2b9-4356-54db-8cca-17b64c39e42c]\n",
      "      From worker 19:\t│   exception = Required dependency Rmath [79098fc4-a85e-5d69-aa6a-4863f24498fa] failed to load from a cache file.\n",
      "      From worker 19:\t└ @ Base loading.jl:969\n",
      "      From worker 26:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for StatsFuns [4c63d2b9-4356-54db-8cca-17b64c39e42c]\n",
      "      From worker 26:\t│   exception = Required dependency SpecialFunctions [276daf66-3868-5448-9aa4-cd146d93841b] failed to load from a cache file.\n",
      "      From worker 26:\t└ @ Base loading.jl:969\n",
      "      From worker 29:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for StatsFuns [4c63d2b9-4356-54db-8cca-17b64c39e42c]\n",
      "      From worker 29:\t│   exception = Required dependency SpecialFunctions [276daf66-3868-5448-9aa4-cd146d93841b] failed to load from a cache file.\n",
      "      From worker 29:\t└ @ Base loading.jl:969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 28:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for StatsFuns [4c63d2b9-4356-54db-8cca-17b64c39e42c]\n",
      "      From worker 28:\t│   exception = Required dependency SpecialFunctions [276daf66-3868-5448-9aa4-cd146d93841b] failed to load from a cache file.\n",
      "      From worker 28:\t└ @ Base loading.jl:969\n",
      "      From worker 20:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for StatsFuns [4c63d2b9-4356-54db-8cca-17b64c39e42c]\n",
      "      From worker 20:\t│   exception = Required dependency SpecialFunctions [276daf66-3868-5448-9aa4-cd146d93841b] failed to load from a cache file.\n",
      "      From worker 20:\t└ @ Base loading.jl:969\n",
      "      From worker 18:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for Distributions [31c24e10-a181-5473-b8eb-7969acd0382f]\n",
      "      From worker 18:\t│   exception = Required dependency SpecialFunctions [276daf66-3868-5448-9aa4-cd146d93841b] failed to load from a cache file.\n",
      "      From worker 18:\t└ @ Base loading.jl:969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The call to compilecache failed to create a usable precompiled cache file for Distributions [31c24e10-a181-5473-b8eb-7969acd0382f]\n",
      "│   exception = Required dependency SpecialFunctions [276daf66-3868-5448-9aa4-cd146d93841b] failed to load from a cache file.\n",
      "└ @ Base loading.jl:969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 18:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for Distributions [31c24e10-a181-5473-b8eb-7969acd0382f]\n",
      "      From worker 18:\t│   exception = Required dependency SpecialFunctions [276daf66-3868-5448-9aa4-cd146d93841b] failed to load from a cache file.\n",
      "      From worker 18:\t└ @ Base loading.jl:969\n",
      "      From worker 18:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for Distributions [31c24e10-a181-5473-b8eb-7969acd0382f]\n",
      "      From worker 18:\t│   exception = Required dependency SpecialFunctions [276daf66-3868-5448-9aa4-cd146d93841b] failed to load from a cache file.\n",
      "      From worker 18:\t└ @ Base loading.jl:969\n",
      "      From worker 19:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for Distributions [31c24e10-a181-5473-b8eb-7969acd0382f]\n",
      "      From worker 19:\t│   exception = ArgumentError: Invalid checksum in cache file /home/bauer/.julia/compiled/v1.1/Distributions/xILW0.ji.\n",
      "      From worker 19:\t└ @ Base loading.jl:969\n",
      "      From worker 19:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for Distributions [31c24e10-a181-5473-b8eb-7969acd0382f]\n",
      "      From worker 19:\t│   exception = Required dependency QuadGK [1fd47b50-473d-5c70-9696-f719f8f3bcdc] failed to load from a cache file.\n",
      "      From worker 19:\t└ @ Base loading.jl:969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The call to compilecache failed to create a usable precompiled cache file for Distributions [31c24e10-a181-5473-b8eb-7969acd0382f]\n",
      "│   exception = Required dependency QuadGK [1fd47b50-473d-5c70-9696-f719f8f3bcdc] failed to load from a cache file.\n",
      "└ @ Base loading.jl:969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 20:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for Distributions [31c24e10-a181-5473-b8eb-7969acd0382f]\n",
      "      From worker 20:\t│   exception = ArgumentError: Invalid checksum in cache file /home/bauer/.julia/compiled/v1.1/Distributions/xILW0.ji.\n",
      "      From worker 20:\t└ @ Base loading.jl:969\n",
      "      From worker 20:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for Distributions [31c24e10-a181-5473-b8eb-7969acd0382f]\n",
      "      From worker 20:\t│   exception = Required dependency QuadGK [1fd47b50-473d-5c70-9696-f719f8f3bcdc] failed to load from a cache file.\n",
      "      From worker 20:\t└ @ Base loading.jl:969\n",
      "      From worker 20:\t┌ Warning: The call to compilecache failed to create a usable precompiled cache file for Distributions [31c24e10-a181-5473-b8eb-7969acd0382f]\n",
      "      From worker 20:\t│   exception = Required dependency QuadGK [1fd47b50-473d-5c70-9696-f719f8f3bcdc] failed to load from a cache file.\n",
      "      From worker 20:\t└ @ Base loading.jl:969\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using Distributions.params in module Main conflicts with an existing identifier.\n",
      "WARNING: using Distributions.var in module Main conflicts with an existing identifier.\n",
      "┌ Warning: `getindex(o::PyObject, s::Symbol)` is deprecated in favor of dot overloading (`getproperty`) so elements should now be accessed as e.g. `o.s` instead of `o[:s]`.\n",
      "│   caller = top-level scope at In[98]:14\n",
      "└ @ Core In[98]:14\n"
     ]
    }
   ],
   "source": [
    "using PyPlot, Distributions\n",
    "\n",
    "# plot circle\n",
    "phis = range(0, stop=2*pi, step=0.01)\n",
    "plot(cos.(phis), sin.(phis))\n",
    "\n",
    "# plot darts\n",
    "N = 400\n",
    "d = Uniform(-1, 1)\n",
    "scatter(rand(d, N), rand(d, N), marker=\".\", color=\"r\")\n",
    "\n",
    "# cosmetics\n",
    "ax = gca()\n",
    "ax[:set_aspect](\"equal\")\n",
    "xlim([-1, 1])\n",
    "ylim([-1, 1])\n",
    "xticks([-1, 0, 1])\n",
    "yticks([-1, 0, 1])\n",
    "nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "1. Write a function `compute_pi(N::Int)` which computes $\\pi$ by throwing $N$ darts as described above.\n",
    "\n",
    "\n",
    "2. Based on 1), write a function `compute_pi_parallel(N::Int, nworkers::Int)` which does the same but divides the work among `ncores` processes.\n",
    "\n",
    "\n",
    "3. Benchmark and compare the methods from 1) and 2).\n",
    "\n",
    "\n",
    "4. Write a function `compute_pi_multiple(Ns::Vector{Int})` which computes $\\pi$ for all given $N$ values. The function should be serial and based on 1).\n",
    "\n",
    "\n",
    "5. Write a function `compute_pi_multiple_parallel(Ns::Vector{Int})` which does the same but in parallel. The function should also be based on 1).\n",
    "\n",
    "\n",
    "6. Benchmark and compare the methods from 4) and 5).\n",
    "\n",
    "\n",
    "7. Calculate $\\pi$ estimates for `Ns = ceil.(Int, exp10.(range(1, stop=8, length=50)))`. Plot $\\pi$ vs $N$ on a semi-log plot.\n",
    "\n",
    "\n",
    "8. Bonus: Write a function `compute_pi_multiple_double_parallel(Ns::Vector{Int})` which computes $\\pi$ for all given $N$ values. The calculation should be as parallel as possible. Multiple different values of $N$ should be calculated at the same time and every one of those calculations should be parallel as well.\n",
    "\n",
    "A reasonable value could be `N = 10_000_000`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If time permits...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMD instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIMD stands for \"Single Instruction Multiple Data\" and falls into the category of instruction level parallelism (vector instructions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mysum(X)\n",
    "    acc = zero(eltype(X))\n",
    "    for i in 1:length(X)\n",
    "        @inbounds acc += X[i]\n",
    "    end\n",
    "    return acc\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about if each loop iteration is independent.\n",
    "\n",
    "Integer addition is **associative** and the order of operations has no impact. Floating-point addition is **non-associative** and the order of operations is important.\n",
    "\n",
    "By using `@simd`, we are asserting several properties of the loop:\n",
    "\n",
    "* It is safe to execute iterations in arbitrary or overlapping order, with special consideration for reduction variables.\n",
    "* Floating-point operations on reduction variables can be reordered, possibly causing different results than without `@simd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mysum_simd(X)\n",
    "    acc = zero(eltype(X))\n",
    "    @simd for i in 1:length(X)\n",
    "        @inbounds acc += X[i]\n",
    "    end\n",
    "    return acc\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rand(Float64, 1000)\n",
    "@btime mysum($X);\n",
    "@btime mysum_simd($X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rand(Int64, 1000)\n",
    "@btime mysum($X);\n",
    "@btime mysum_simd($X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rand(Float64, 1000)\n",
    "s = mysum(X);\n",
    "s_simd = mysum_simd(X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s == s_simd # will sometimes be false!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(s-s_simd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Linux/MacOS:\n",
    "\n",
    "```bash\n",
    "export JULIA_NUM_THREADS=4\n",
    "```\n",
    "\n",
    "On Windows:\n",
    "\n",
    "```bash\n",
    "set JULIA_NUM_THREADS=4\n",
    "```\n",
    "\n",
    "Afterwards start julia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Switching to REPL to demonstrate this...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```julia\n",
    "using Base.Threads\n",
    "\n",
    "# How many threads are we running on?\n",
    "nthreads()\n",
    "\n",
    "# How many processes are we running?\n",
    "using Distributed; nprocs()\n",
    "\n",
    "# Fill an array in parallel\n",
    "a = zeros(nthreads()*10)\n",
    "@threads for i in 1:length(a)\n",
    "    a[i] = threadid()\n",
    "end\n",
    "```\n",
    "\n",
    "Note that we do not need to use a `SharedArray` or similar here since threads are process shared memory. Although convenient in this example, this fact can potentially lead to *thread safety* and *race condition* issues where different threads access the same piece of memory. Writing fast thread safe code isn't trivial!\n",
    "\n",
    "See for example the sections [Atomic Operations](https://docs.julialang.org/en/stable/manual/parallel-computing/#Atomic-Operations-1) and [Side effects and mutable function arguments](https://docs.julialang.org/en/stable/manual/parallel-computing/#Side-effects-and-mutable-function-arguments-1) of the Julia documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPI.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple wrapper to the Message Passing Interface (MPI).\n",
    "\n",
    "Github: https://github.com/JuliaParallel/MPI.jl\n",
    "\n",
    "Example usage:\n",
    "\n",
    "```julia\n",
    "import MPI\n",
    "\n",
    "MPI.Init()\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "MPI.Barrier(comm)\n",
    "\n",
    "root = 0\n",
    "r = MPI.Comm_rank(comm)\n",
    "\n",
    "sr = MPI.Reduce(r, MPI.SUM, root, comm)\n",
    "\n",
    "if(MPI.Comm_rank(comm) == root)\n",
    "   @printf(\"sum of ranks: %s\\n\", sr)\n",
    "end\n",
    "\n",
    "MPI.Finalize()\n",
    "```\n",
    "\n",
    "Run as\n",
    "```\n",
    "mpirun -np 4 ./julia example.jl\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
